# Experiment

## Overview

This module automates the experimental analysis of a test-oracle generator (TOG) for the task of automated test generation. 

A unit test is composed of two parts: **the prefix** and **the oracle**. 

```agsl
// prefix
int a = 5;
int b = 1;
// oracle
assert sum(a, b) == (a + b)
```

To generate test prefixes, we use [EvoSuite](https://www.evosuite.org/), which generates complete unit tests (including the oracle), and remove the generated oracles (assertions) using [JavaParser](https://javaparser.org/). Then, we generate new oracles using an arbitrary TOG, and add these assertions to the test prefixes. Finally, we use [PITest](https://pitest.org/) to report mutation score and also record the number of positive/negative tests (see [Metrics](#metrics) below).

To analyze a TOG, run
```agsl
python3 experiment.py [tog] [source path]
```
where TOG is "jdoctor", "toga", or "tratto". For example,
```agsl
python3 experiment.py tratto ../path/to/source/File.java
```

## Research Questions

As a precursor, we define an "axiomatic" oracle, as a self-evident and unquestionable oracle (e.g. `methodResult != null`). Axiomatic oracles are very general and typically not specific to individual test prefixes. An example of a non-axiomatic oracle is: `sum(5, 1) == 6`.

In our experimental analysis, we seek to answer the following research questions:

1. What is the effectiveness (precision and FPR) of `Tratto` for generating axiomatic oracles?
2. How does `Tratto` enhance test suites when combined with tools such as `EvoSuite` or `Randoop` in terms of precision, false-positives, and bug-finding ability?
3. Is `Tratto` able to recreate all (or more) axiomatic oracles generated by `JDoctor`? Is `Tratto` able to synthesize all oracles (and fix wrong oracles) generated by `TOGA`?

[comment]: <> (4. How does `Tratto` compare with `ChatGPT` for axiomatic oracle generation?)

## Metrics

To answer the above research questions, we perform two experiments: [Classification](#classification) (RQ 1, 3) and [Mutation](#mutation) (RQ 2).

### Classification

We say an oracle <span style="color:red">"fails"</span> the code if its corresponding test assertion fails using the current implementation. We say an oracle <span style="color:green">"passes"</span> the specification if the assertion *should* pass according to the specification.

|                     | Code                                  | Specification                         |
|---------------------|---------------------------------------|---------------------------------------|
| True Positive (TP)  | <span style="color:red">Fail</span>   | <span style="color:green">Pass</span> |
| False Positive (FP) | <span style="color:red">Fail</span>   | <span style="color:red">Fail</span>   |
| True Negative (TN)  | <span style="color:green">Pass</span> | <span style="color:green">Pass</span> |
| False Negative (FN) | <span style="color:green">Pass</span> | <span style="color:red">Fail</span>   |

For clarification, consider the following (buggy) code snippet:

```agsl
/**
 * @param a an integer
 * @param b an integer
 * @returns the sum of the two integer values
 */
int sum(int a, int b) {
    return a - b;
}
```

We provide an example of each class of oracle below:
- True Positive: `sum(a, b) == (a + b)`
- False Positive: `sum(a, b) == null`
- True Negative: `sum(a, b) != null`
- False Negative: `sum(a, b) == (a - b)`

Intuitively, we hope to maximize True Positives and True Negatives, and minimize False Positives and False Negatives. This corresponds to a high precision and a low FPR.

### Mutation

To analyze the "effectiveness" of the generated oracles, we compute the mutation score of the generated test suite. Consider the previous example, `sum`, and two corresponding oracles: `sum(a, b) == (a + b)` and `sum(a, b) != null`. We say the first assertion (1) is more "effective" than the second assertion (2). We quantify "effective"-ness via mutation score, which indicates how robust the test suite is to changes in source code. Intuitively, because (1) implies (2), we know that (1) will always kill more mutants than (2) and have a better mutation score.

## Implementation

The user provides two arguments as input: the TOG and the source path. For reference, we provide an overview of the experimental pipeline.

![experiment pipeline](./doc/experiment-pipeline.png)

We provide a brief description of the relevant files:

- `generator`: this package contains scripts for generating test prefixes and test oracles 
  - `prefix.sh`: a script that invokes EvoSuite for a given source file
  - `jdoctor.sh`: a script that invokes JDoctor for a given source file
  - `toga.sh`: a script that invokes TOGA for a given source file and test prefix
  - `tratto.sh`: a script that invokes Tratto for a given source file
- `src/main/java`: this package contains all Java functionality, including mutation testing, file IO, JavaParser utilities, etc.
  - `FileUtils.java`: a class for reading and writing files
  - `TestAnalyzer.java`: a class for reporting statistics for a test suite. Includes the number of passing/failing tests and mutation score.
  - `TestUtils.java`: a class for test utilities, such as removing/adding assertions
- `experiment.py`: the end-to-end script which performs the experiment

### Prefix

We run `evosuite.sh` to generate a test suite using EvoSuite. These full test cases include both the test prefix and the test oracle, and are saved in `experiment/output/evosuite-test/`. Then, we use `TestUtils.java` to remove the oracles (assertions) using JavaParser. These test prefixes are saved as separate files in `experiment/output/evosuite-prefix`.

### Oracle

We use the EvoSuite prefixes to generate oracles using the specified TOG. Each TOG has a corresponding script invoking the TOG (as a jar file). Then, we use `TestUtils.java` to insert the new oracles, using JavaParser, as assertions in the test prefixes. These new tests are saved as separate files in `experiment/output/tog-test/[tog]/`, where `[tog]` is the specified TOG. 

### Analysis

We use the generated tests in `experiment/output/tog-test/[tog]/` and report statistics using `TestAnalyzer.java`. 



