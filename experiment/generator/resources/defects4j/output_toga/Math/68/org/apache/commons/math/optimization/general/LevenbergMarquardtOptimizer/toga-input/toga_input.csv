focal_method,test_prefix,docstring
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return new VectorialPointValuePair(point, objective);
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            // tests for convergence.
            // we use the vectorial convergence checker
            // we use the Levenberg-Marquardt specific convergence parameters
            if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                return new VectorialPointValuePair(point, objective);
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(""cost relative tolerance is too small ({0}),"" + "" no further reduction in the"" + "" sum of squares is possible"", costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(""parameters relative tolerance is too small"" + "" ({0}), no further improvement in"" + "" the approximate solution is possible"", parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(""orthogonality tolerance is too small ({0}),"" + "" solution is orthogonal to the jacobian"", orthoTolerance);
            }
        }
    }
}","public void test000() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    levenbergMarquardtOptimizer0.checker = null;
    levenbergMarquardtOptimizer0.setMaxIterations(2145241826);
    double[][] doubleArray0 = new double[2][9];
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn((Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0).when(multivariateMatrixFunction0).value(any(double[].class));
    double[] doubleArray1 = new double[2];
    double[] doubleArray2 = new double[2];
    levenbergMarquardtOptimizer0.setOrthoTolerance((-0.0023295157986838455));
    doubleArray2[0] = Double.NEGATIVE_INFINITY;
    doubleArray1[0] = (double) 100;
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray1, (Object) doubleArray1, (Object) doubleArray2, (Object) doubleArray2, (Object) null).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
    levenbergMarquardtOptimizer0.doOptimize();
    doubleArray0[0] = doubleArray1;
    levenbergMarquardtOptimizer0.setOrthoTolerance((-869.9265));
    levenbergMarquardtOptimizer0.doOptimize();
}","/**
 * {@inheritDoc}
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return new VectorialPointValuePair(point, objective);
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            // tests for convergence.
            // we use the vectorial convergence checker
            // we use the Levenberg-Marquardt specific convergence parameters
            if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                return new VectorialPointValuePair(point, objective);
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(""cost relative tolerance is too small ({0}),"" + "" no further reduction in the"" + "" sum of squares is possible"", costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(""parameters relative tolerance is too small"" + "" ({0}), no further improvement in"" + "" the approximate solution is possible"", parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(""orthogonality tolerance is too small ({0}),"" + "" solution is orthogonal to the jacobian"", orthoTolerance);
            }
        }
    }
}","public void test011() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    levenbergMarquardtOptimizer0.setMaxIterations(100);
    levenbergMarquardtOptimizer0.cols = 100;
    levenbergMarquardtOptimizer0.doOptimize();
}","/**
 * {@inheritDoc}
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return new VectorialPointValuePair(point, objective);
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            // tests for convergence.
            // we use the vectorial convergence checker
            // we use the Levenberg-Marquardt specific convergence parameters
            if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                return new VectorialPointValuePair(point, objective);
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(""cost relative tolerance is too small ({0}),"" + "" no further reduction in the"" + "" sum of squares is possible"", costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(""parameters relative tolerance is too small"" + "" ({0}), no further improvement in"" + "" the approximate solution is possible"", parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(""orthogonality tolerance is too small ({0}),"" + "" solution is orthogonal to the jacobian"", orthoTolerance);
            }
        }
    }
}","public void test022() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    double[] doubleArray0 = new double[2];
    doubleArray0[0] = (double) 100;
    doubleArray0[1] = (double) 100;
    levenbergMarquardtOptimizer0.targetValues = doubleArray0;
    double[][] doubleArray1 = new double[2][9];
    levenbergMarquardtOptimizer0.setOrthoTolerance((-366.832791744));
    double[][] doubleArray2 = new double[9][5];
    doubleArray2[0] = levenbergMarquardtOptimizer0.targetValues;
    doubleArray2[1] = doubleArray0;
    double[] doubleArray3 = new double[9];
    doubleArray3[0] = (double) 100;
    doubleArray3[1] = (double) 100;
    doubleArray3[2] = (double) 100;
    doubleArray3[3] = (-366.832791744);
    doubleArray3[4] = (-366.832791744);
    doubleArray3[5] = (-366.832791744);
    doubleArray3[6] = (-366.832791744);
    doubleArray3[7] = (double) 100;
    doubleArray3[8] = (double) 100;
    doubleArray2[2] = doubleArray3;
    doubleArray2[3] = doubleArray0;
    doubleArray2[4] = doubleArray0;
    doubleArray2[5] = levenbergMarquardtOptimizer0.targetValues;
    doubleArray2[6] = levenbergMarquardtOptimizer0.targetValues;
    doubleArray2[7] = doubleArray0;
    doubleArray2[8] = levenbergMarquardtOptimizer0.targetValues;
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn((Object) doubleArray1, (Object) doubleArray1, (Object) doubleArray2).when(multivariateMatrixFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.incrementIterationsCounter();
    levenbergMarquardtOptimizer0.setCostRelativeTolerance(2133.2388509050966);
    levenbergMarquardtOptimizer0.setInitialStepBoundFactor(304.0775);
    double[] doubleArray4 = new double[2];
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray4, (Object) doubleArray4, (Object) doubleArray0, (Object) doubleArray4, (Object) doubleArray0).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray4, doubleArray4, doubleArray4);
    levenbergMarquardtOptimizer0.setMaxIterations(120);
    levenbergMarquardtOptimizer0.doOptimize();
    levenbergMarquardtOptimizer0.doOptimize();
}","/**
 * {@inheritDoc}
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return new VectorialPointValuePair(point, objective);
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            // tests for convergence.
            // we use the vectorial convergence checker
            // we use the Levenberg-Marquardt specific convergence parameters
            if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                return new VectorialPointValuePair(point, objective);
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(""cost relative tolerance is too small ({0}),"" + "" no further reduction in the"" + "" sum of squares is possible"", costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(""parameters relative tolerance is too small"" + "" ({0}), no further improvement in"" + "" the approximate solution is possible"", parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(""orthogonality tolerance is too small ({0}),"" + "" solution is orthogonal to the jacobian"", orthoTolerance);
            }
        }
    }
}","public void test033() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    levenbergMarquardtOptimizer0.checker = null;
    double[][] doubleArray0 = new double[2][9];
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn((Object) doubleArray0, (Object) doubleArray0).when(multivariateMatrixFunction0).value(any(double[].class));
    double[] doubleArray1 = new double[2];
    double[] doubleArray2 = new double[2];
    levenbergMarquardtOptimizer0.setOrthoTolerance(0.25);
    doubleArray2[0] = Double.NEGATIVE_INFINITY;
    doubleArray1[0] = (double) 100;
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray1, (Object) doubleArray1, (Object) doubleArray2).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
    doubleArray0[0] = doubleArray1;
    levenbergMarquardtOptimizer0.setOrthoTolerance((-869.9265));
    levenbergMarquardtOptimizer0.doOptimize();
}","/**
 * {@inheritDoc}
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return new VectorialPointValuePair(point, objective);
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            // tests for convergence.
            // we use the vectorial convergence checker
            // we use the Levenberg-Marquardt specific convergence parameters
            if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                return new VectorialPointValuePair(point, objective);
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(""cost relative tolerance is too small ({0}),"" + "" no further reduction in the"" + "" sum of squares is possible"", costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(""parameters relative tolerance is too small"" + "" ({0}), no further improvement in"" + "" the approximate solution is possible"", parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(""orthogonality tolerance is too small ({0}),"" + "" solution is orthogonal to the jacobian"", orthoTolerance);
            }
        }
    }
}","public void test044() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    // Undeclared exception!
    try {
        levenbergMarquardtOptimizer0.doOptimize();
        fail(""Expecting exception: NullPointerException"");
    } catch (NullPointerException e) {
        //
        // no message in exception (getMessage() returned null)
        //
        verifyException(""org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer"", e);
    }
}","/**
 * {@inheritDoc}
 */"
"public void setParRelativeTolerance(double parRelativeTolerance) {
    this.parRelativeTolerance = parRelativeTolerance;
}","public void test055() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    levenbergMarquardtOptimizer0.setInitialStepBoundFactor(2028.36210992623);
    levenbergMarquardtOptimizer0.setInitialStepBoundFactor(2028.36210992623);
    double double0 = 722.4;
    levenbergMarquardtOptimizer0.setParRelativeTolerance(722.4);
    SimpleVectorialValueChecker simpleVectorialValueChecker0 = new SimpleVectorialValueChecker((-1721.36667), (-3471.442816367518));
    levenbergMarquardtOptimizer0.setConvergenceChecker(simpleVectorialValueChecker0);
    levenbergMarquardtOptimizer0.setParRelativeTolerance(0.0);
    levenbergMarquardtOptimizer0.setCostRelativeTolerance(0.0);
    levenbergMarquardtOptimizer0.doOptimize();
    levenbergMarquardtOptimizer0.setParRelativeTolerance(double0);
}","/**
 * Set the desired relative error in the approximate solution parameters.
 * <p>This setting is used only if the {@link #setConvergenceChecker vectorial
 * convergence checker} is set to null.</p>
 * @param parRelativeTolerance desired relative error
 * in the approximate solution parameters
 */"
"public void setOrthoTolerance(double orthoTolerance) {
    this.orthoTolerance = orthoTolerance;
}","public void test066() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    levenbergMarquardtOptimizer0.setOrthoTolerance(0.0);
}","/**
 * Set the desired max cosine on the orthogonality.
 * <p>This setting is always used, regardless of the {@link #setConvergenceChecker
 * vectorial convergence checker} being null or non-null.</p>
 * @param orthoTolerance desired max cosine on the orthogonality
 * between the function vector and the columns of the jacobian
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return new VectorialPointValuePair(point, objective);
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            // tests for convergence.
            // we use the vectorial convergence checker
            // we use the Levenberg-Marquardt specific convergence parameters
            if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                return new VectorialPointValuePair(point, objective);
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(""cost relative tolerance is too small ({0}),"" + "" no further reduction in the"" + "" sum of squares is possible"", costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(""parameters relative tolerance is too small"" + "" ({0}), no further improvement in"" + "" the approximate solution is possible"", parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(""orthogonality tolerance is too small ({0}),"" + "" solution is orthogonal to the jacobian"", orthoTolerance);
            }
        }
    }
}","public void test077() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    levenbergMarquardtOptimizer0.rows = (-2562);
    levenbergMarquardtOptimizer0.checker = null;
    levenbergMarquardtOptimizer0.doOptimize();
    levenbergMarquardtOptimizer0.doOptimize();
    // Undeclared exception!
    try {
        levenbergMarquardtOptimizer0.doOptimize();
        fail(""Expecting exception: NegativeArraySizeException"");
    } catch (NegativeArraySizeException e) {
        //
        // no message in exception (getMessage() returned null)
        //
        verifyException(""org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer"", e);
    }
}","/**
 * {@inheritDoc}
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return new VectorialPointValuePair(point, objective);
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            // tests for convergence.
            // we use the vectorial convergence checker
            // we use the Levenberg-Marquardt specific convergence parameters
            if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                return new VectorialPointValuePair(point, objective);
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(""cost relative tolerance is too small ({0}),"" + "" no further reduction in the"" + "" sum of squares is possible"", costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(""parameters relative tolerance is too small"" + "" ({0}), no further improvement in"" + "" the approximate solution is possible"", parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(""orthogonality tolerance is too small ({0}),"" + "" solution is orthogonal to the jacobian"", orthoTolerance);
            }
        }
    }
}","public void test088() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    levenbergMarquardtOptimizer0.rows = 1910;
    levenbergMarquardtOptimizer0.doOptimize();
    // Undeclared exception!
    try {
        levenbergMarquardtOptimizer0.doOptimize();
        fail(""Expecting exception: NullPointerException"");
    } catch (NullPointerException e) {
        //
        // no message in exception (getMessage() returned null)
        //
        verifyException(""org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer"", e);
    }
}","/**
 * {@inheritDoc}
 */"
"public void setCostRelativeTolerance(double costRelativeTolerance) {
    this.costRelativeTolerance = costRelativeTolerance;
}","public void test1010() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    double[][] doubleArray0 = new double[2][9];
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn((Object) doubleArray0, (Object) null).when(multivariateMatrixFunction0).value(any(double[].class));
    double[] doubleArray1 = new double[2];
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray1, (Object) null).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
    levenbergMarquardtOptimizer0.incrementIterationsCounter();
    double[] doubleArray2 = new double[0];
    levenbergMarquardtOptimizer0.doOptimize();
    doubleArray0[0] = doubleArray2;
    double[] doubleArray3 = new double[4];
    doubleArray3[0] = (double) 100;
    doubleArray3[1] = (double) 100;
    doubleArray3[2] = (double) 100;
    doubleArray3[3] = (double) 100;
    doubleArray0[1] = doubleArray3;
    levenbergMarquardtOptimizer0.jacobian = doubleArray0;
    levenbergMarquardtOptimizer0.rows = 100;
    levenbergMarquardtOptimizer0.rows = 100;
    levenbergMarquardtOptimizer0.setCostRelativeTolerance(2992.683);
}","/**
 * Set the desired relative error in the sum of squares.
 * <p>This setting is used only if the {@link #setConvergenceChecker vectorial
 * convergence checker} is set to null.</p>
 * @param costRelativeTolerance desired relative error in the sum of squares
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return new VectorialPointValuePair(point, objective);
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            // tests for convergence.
            // we use the vectorial convergence checker
            // we use the Levenberg-Marquardt specific convergence parameters
            if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                return new VectorialPointValuePair(point, objective);
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(""cost relative tolerance is too small ({0}),"" + "" no further reduction in the"" + "" sum of squares is possible"", costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(""parameters relative tolerance is too small"" + "" ({0}), no further improvement in"" + "" the approximate solution is possible"", parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(""orthogonality tolerance is too small ({0}),"" + "" solution is orthogonal to the jacobian"", orthoTolerance);
            }
        }
    }
}","public void test1111() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    double[][] doubleArray0 = new double[2][9];
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn((Object) doubleArray0, (Object) doubleArray0).when(multivariateMatrixFunction0).value(any(double[].class));
    double[] doubleArray1 = new double[2];
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray1, (Object) doubleArray1, (Object) null).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
    levenbergMarquardtOptimizer0.incrementIterationsCounter();
    double[] doubleArray2 = new double[0];
    levenbergMarquardtOptimizer0.doOptimize();
    doubleArray0[0] = doubleArray2;
    double[] doubleArray3 = new double[4];
    doubleArray3[0] = (double) 100;
    doubleArray3[1] = (double) 100;
    doubleArray3[3] = (double) 100;
    doubleArray0[1] = doubleArray3;
    levenbergMarquardtOptimizer0.jacobian = doubleArray0;
    levenbergMarquardtOptimizer0.rows = 100;
    levenbergMarquardtOptimizer0.rows = 100;
    levenbergMarquardtOptimizer0.setCostRelativeTolerance(2992.683);
    levenbergMarquardtOptimizer0.doOptimize();
}","/**
 * {@inheritDoc}
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return new VectorialPointValuePair(point, objective);
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            // tests for convergence.
            // we use the vectorial convergence checker
            // we use the Levenberg-Marquardt specific convergence parameters
            if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                return new VectorialPointValuePair(point, objective);
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(""cost relative tolerance is too small ({0}),"" + "" no further reduction in the"" + "" sum of squares is possible"", costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(""parameters relative tolerance is too small"" + "" ({0}), no further improvement in"" + "" the approximate solution is possible"", parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(""orthogonality tolerance is too small ({0}),"" + "" solution is orthogonal to the jacobian"", orthoTolerance);
            }
        }
    }
}","public void test1313() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    double[][] doubleArray0 = new double[2][9];
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn((Object) doubleArray0, (Object) doubleArray0, (Object) null).when(multivariateMatrixFunction0).value(any(double[].class));
    double[] doubleArray1 = new double[2];
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray1, (Object) doubleArray1, (Object) null).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
    levenbergMarquardtOptimizer0.incrementIterationsCounter();
    double[] doubleArray2 = new double[0];
    levenbergMarquardtOptimizer0.doOptimize();
    doubleArray0[0] = doubleArray2;
    double[] doubleArray3 = new double[4];
    doubleArray3[0] = (double) 100;
    doubleArray3[1] = (double) 100;
    doubleArray3[3] = (double) 100;
    doubleArray0[1] = doubleArray3;
    levenbergMarquardtOptimizer0.jacobian = doubleArray0;
    levenbergMarquardtOptimizer0.setCostRelativeTolerance(2992.683);
    levenbergMarquardtOptimizer0.doOptimize();
}","/**
 * {@inheritDoc}
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return new VectorialPointValuePair(point, objective);
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            // tests for convergence.
            // we use the vectorial convergence checker
            // we use the Levenberg-Marquardt specific convergence parameters
            if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                return new VectorialPointValuePair(point, objective);
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(""cost relative tolerance is too small ({0}),"" + "" no further reduction in the"" + "" sum of squares is possible"", costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(""parameters relative tolerance is too small"" + "" ({0}), no further improvement in"" + "" the approximate solution is possible"", parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(""orthogonality tolerance is too small ({0}),"" + "" solution is orthogonal to the jacobian"", orthoTolerance);
            }
        }
    }
}","public void test1414() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    double[][] doubleArray0 = new double[2][9];
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn((Object) doubleArray0, (Object) doubleArray0, (Object) null, (Object) null).when(multivariateMatrixFunction0).value(any(double[].class));
    double[] doubleArray1 = new double[2];
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray1, (Object) doubleArray1, (Object) null, (Object) null).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
    levenbergMarquardtOptimizer0.doOptimize();
    doubleArray0[0] = doubleArray1;
    doubleArray1[0] = (double) 100;
    levenbergMarquardtOptimizer0.doOptimize();
    levenbergMarquardtOptimizer0.doOptimize();
}","/**
 * {@inheritDoc}
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return new VectorialPointValuePair(point, objective);
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            // tests for convergence.
            // we use the vectorial convergence checker
            // we use the Levenberg-Marquardt specific convergence parameters
            if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                return new VectorialPointValuePair(point, objective);
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(""cost relative tolerance is too small ({0}),"" + "" no further reduction in the"" + "" sum of squares is possible"", costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(""parameters relative tolerance is too small"" + "" ({0}), no further improvement in"" + "" the approximate solution is possible"", parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(""orthogonality tolerance is too small ({0}),"" + "" solution is orthogonal to the jacobian"", orthoTolerance);
            }
        }
    }
}","public void test1515() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    levenbergMarquardtOptimizer0.checker = null;
    double[][] doubleArray0 = new double[2][9];
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn((Object) doubleArray0, (Object) doubleArray0, (Object) null).when(multivariateMatrixFunction0).value(any(double[].class));
    double[] doubleArray1 = new double[2];
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray1, (Object) doubleArray1, (Object) null, (Object) null).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
    levenbergMarquardtOptimizer0.doOptimize();
    doubleArray0[0] = doubleArray1;
    levenbergMarquardtOptimizer0.setOrthoTolerance((-869.9265));
    levenbergMarquardtOptimizer0.doOptimize();
}","/**
 * {@inheritDoc}
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return new VectorialPointValuePair(point, objective);
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            // tests for convergence.
            // we use the vectorial convergence checker
            // we use the Levenberg-Marquardt specific convergence parameters
            if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                return new VectorialPointValuePair(point, objective);
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(""cost relative tolerance is too small ({0}),"" + "" no further reduction in the"" + "" sum of squares is possible"", costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(""parameters relative tolerance is too small"" + "" ({0}), no further improvement in"" + "" the approximate solution is possible"", parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(""orthogonality tolerance is too small ({0}),"" + "" solution is orthogonal to the jacobian"", orthoTolerance);
            }
        }
    }
}","public void test1616() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    levenbergMarquardtOptimizer0.checker = null;
    double[][] doubleArray0 = new double[2][9];
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn((Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0).when(multivariateMatrixFunction0).value(any(double[].class));
    double[] doubleArray1 = new double[2];
    double[] doubleArray2 = new double[2];
    doubleArray2[0] = Double.NEGATIVE_INFINITY;
    doubleArray2[1] = (double) 100;
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray1, (Object) doubleArray1, (Object) doubleArray2, (Object) doubleArray2).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
    levenbergMarquardtOptimizer0.doOptimize();
    doubleArray0[0] = doubleArray1;
    levenbergMarquardtOptimizer0.setOrthoTolerance((-869.9265));
    levenbergMarquardtOptimizer0.doOptimize();
}","/**
 * {@inheritDoc}
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return new VectorialPointValuePair(point, objective);
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            // tests for convergence.
            // we use the vectorial convergence checker
            // we use the Levenberg-Marquardt specific convergence parameters
            if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                return new VectorialPointValuePair(point, objective);
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(""cost relative tolerance is too small ({0}),"" + "" no further reduction in the"" + "" sum of squares is possible"", costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(""parameters relative tolerance is too small"" + "" ({0}), no further improvement in"" + "" the approximate solution is possible"", parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(""orthogonality tolerance is too small ({0}),"" + "" solution is orthogonal to the jacobian"", orthoTolerance);
            }
        }
    }
}","public void test1717() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    double[] doubleArray0 = new double[2];
    doubleArray0[0] = (double) 100;
    doubleArray0[1] = (double) 100;
    levenbergMarquardtOptimizer0.targetValues = doubleArray0;
    double[][] doubleArray1 = new double[2][9];
    levenbergMarquardtOptimizer0.setOrthoTolerance((-366.832791744));
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn((Object) doubleArray1, (Object) doubleArray1, (Object) null).when(multivariateMatrixFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.incrementIterationsCounter();
    levenbergMarquardtOptimizer0.setCostRelativeTolerance(2133.2388509050966);
    levenbergMarquardtOptimizer0.setInitialStepBoundFactor(304.0775);
    double[] doubleArray2 = new double[2];
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray2, (Object) doubleArray2, (Object) doubleArray0, (Object) doubleArray2, (Object) null).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray2, doubleArray2, doubleArray2);
    levenbergMarquardtOptimizer0.setMaxIterations(120);
    levenbergMarquardtOptimizer0.doOptimize();
    levenbergMarquardtOptimizer0.doOptimize();
}","/**
 * {@inheritDoc}
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return new VectorialPointValuePair(point, objective);
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            // tests for convergence.
            // we use the vectorial convergence checker
            // we use the Levenberg-Marquardt specific convergence parameters
            if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                return new VectorialPointValuePair(point, objective);
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(""cost relative tolerance is too small ({0}),"" + "" no further reduction in the"" + "" sum of squares is possible"", costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(""parameters relative tolerance is too small"" + "" ({0}), no further improvement in"" + "" the approximate solution is possible"", parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(""orthogonality tolerance is too small ({0}),"" + "" solution is orthogonal to the jacobian"", orthoTolerance);
            }
        }
    }
}","public void test1919() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    levenbergMarquardtOptimizer0.checker = null;
    double[][] doubleArray0 = new double[2][9];
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn((Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0).when(multivariateMatrixFunction0).value(any(double[].class));
    double[] doubleArray1 = new double[2];
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray1, (Object) doubleArray1, (Object) doubleArray1, (Object) doubleArray1, (Object) doubleArray1).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
    levenbergMarquardtOptimizer0.doOptimize();
    levenbergMarquardtOptimizer0.cols = 0;
    doubleArray0[0] = doubleArray1;
    levenbergMarquardtOptimizer0.setOrthoTolerance((-869.9265));
    levenbergMarquardtOptimizer0.doOptimize();
    levenbergMarquardtOptimizer0.doOptimize();
    levenbergMarquardtOptimizer0.doOptimize();
    levenbergMarquardtOptimizer0.doOptimize();
    levenbergMarquardtOptimizer0.doOptimize();
}","/**
 * {@inheritDoc}
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return new VectorialPointValuePair(point, objective);
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            // tests for convergence.
            // we use the vectorial convergence checker
            // we use the Levenberg-Marquardt specific convergence parameters
            if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                return new VectorialPointValuePair(point, objective);
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(""cost relative tolerance is too small ({0}),"" + "" no further reduction in the"" + "" sum of squares is possible"", costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(""parameters relative tolerance is too small"" + "" ({0}), no further improvement in"" + "" the approximate solution is possible"", parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(""orthogonality tolerance is too small ({0}),"" + "" solution is orthogonal to the jacobian"", orthoTolerance);
            }
        }
    }
}","public void test2020() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    levenbergMarquardtOptimizer0.checker = null;
    double[][] doubleArray0 = new double[2][9];
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn((Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0, (Object) null).when(multivariateMatrixFunction0).value(any(double[].class));
    double[] doubleArray1 = new double[2];
    double[] doubleArray2 = new double[2];
    levenbergMarquardtOptimizer0.setOrthoTolerance(0.25);
    doubleArray2[0] = Double.NEGATIVE_INFINITY;
    doubleArray1[0] = (double) 100;
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray1, (Object) doubleArray1, (Object) doubleArray2, (Object) doubleArray2).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
    levenbergMarquardtOptimizer0.doOptimize();
    doubleArray0[0] = doubleArray1;
    levenbergMarquardtOptimizer0.setOrthoTolerance((-869.9265));
    levenbergMarquardtOptimizer0.doOptimize();
}","/**
 * {@inheritDoc}
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return new VectorialPointValuePair(point, objective);
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            // tests for convergence.
            // we use the vectorial convergence checker
            // we use the Levenberg-Marquardt specific convergence parameters
            if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                return new VectorialPointValuePair(point, objective);
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(""cost relative tolerance is too small ({0}),"" + "" no further reduction in the"" + "" sum of squares is possible"", costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(""parameters relative tolerance is too small"" + "" ({0}), no further improvement in"" + "" the approximate solution is possible"", parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(""orthogonality tolerance is too small ({0}),"" + "" solution is orthogonal to the jacobian"", orthoTolerance);
            }
        }
    }
}","public void test2121() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    levenbergMarquardtOptimizer0.checker = null;
    double[][] doubleArray0 = new double[2][9];
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn((Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0).when(multivariateMatrixFunction0).value(any(double[].class));
    double[] doubleArray1 = new double[2];
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray1, (Object) doubleArray1, (Object) doubleArray1, (Object) doubleArray1).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
    levenbergMarquardtOptimizer0.doOptimize();
    doubleArray0[0] = doubleArray1;
    levenbergMarquardtOptimizer0.setOrthoTolerance((-869.9265));
    levenbergMarquardtOptimizer0.setInitialStepBoundFactor((-869.9265));
    levenbergMarquardtOptimizer0.doOptimize();
    levenbergMarquardtOptimizer0.doOptimize();
    levenbergMarquardtOptimizer0.doOptimize();
    try {
        levenbergMarquardtOptimizer0.doOptimize();
        fail(""Expecting exception: Exception"");
    } catch (Exception e) {
        //
        // orthogonality tolerance is too small (-869.927), solution is orthogonal to the jacobian
        //
        verifyException(""org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer"", e);
    }
}","/**
 * {@inheritDoc}
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return new VectorialPointValuePair(point, objective);
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            // tests for convergence.
            // we use the vectorial convergence checker
            // we use the Levenberg-Marquardt specific convergence parameters
            if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                return new VectorialPointValuePair(point, objective);
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(""cost relative tolerance is too small ({0}),"" + "" no further reduction in the"" + "" sum of squares is possible"", costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(""parameters relative tolerance is too small"" + "" ({0}), no further improvement in"" + "" the approximate solution is possible"", parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(""orthogonality tolerance is too small ({0}),"" + "" solution is orthogonal to the jacobian"", orthoTolerance);
            }
        }
    }
}","public void test2222() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    levenbergMarquardtOptimizer0.checker = null;
    double[][] doubleArray0 = new double[2][9];
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn((Object) doubleArray0, (Object) doubleArray0).when(multivariateMatrixFunction0).value(any(double[].class));
    double[] doubleArray1 = new double[2];
    double[] doubleArray2 = new double[2];
    levenbergMarquardtOptimizer0.setOrthoTolerance(0.25);
    doubleArray2[0] = Double.NEGATIVE_INFINITY;
    doubleArray1[0] = (double) 100;
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray1, (Object) doubleArray1, (Object) doubleArray2).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
    VectorialPointValuePair vectorialPointValuePair0 = new VectorialPointValuePair(doubleArray1, doubleArray2);
    doubleArray0[0] = doubleArray1;
    levenbergMarquardtOptimizer0.setOrthoTolerance((-869.9265));
    levenbergMarquardtOptimizer0.doOptimize();
}","/**
 * {@inheritDoc}
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return new VectorialPointValuePair(point, objective);
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            // tests for convergence.
            // we use the vectorial convergence checker
            // we use the Levenberg-Marquardt specific convergence parameters
            if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                return new VectorialPointValuePair(point, objective);
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(""cost relative tolerance is too small ({0}),"" + "" no further reduction in the"" + "" sum of squares is possible"", costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(""parameters relative tolerance is too small"" + "" ({0}), no further improvement in"" + "" the approximate solution is possible"", parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(""orthogonality tolerance is too small ({0}),"" + "" solution is orthogonal to the jacobian"", orthoTolerance);
            }
        }
    }
}","public void test2323() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    levenbergMarquardtOptimizer0.checker = null;
    double[][] doubleArray0 = new double[2][9];
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn((Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0).when(multivariateMatrixFunction0).value(any(double[].class));
    double[] doubleArray1 = new double[2];
    double[] doubleArray2 = new double[2];
    levenbergMarquardtOptimizer0.setOrthoTolerance(0.25);
    doubleArray2[0] = Double.NEGATIVE_INFINITY;
    doubleArray1[0] = (double) 100;
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray1, (Object) doubleArray1, (Object) doubleArray2, (Object) doubleArray2).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
    levenbergMarquardtOptimizer0.doOptimize();
    doubleArray0[1] = doubleArray1;
    levenbergMarquardtOptimizer0.setOrthoTolerance((-869.9265));
    levenbergMarquardtOptimizer0.doOptimize();
}","/**
 * {@inheritDoc}
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return new VectorialPointValuePair(point, objective);
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            // tests for convergence.
            // we use the vectorial convergence checker
            // we use the Levenberg-Marquardt specific convergence parameters
            if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                return new VectorialPointValuePair(point, objective);
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(""cost relative tolerance is too small ({0}),"" + "" no further reduction in the"" + "" sum of squares is possible"", costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(""parameters relative tolerance is too small"" + "" ({0}), no further improvement in"" + "" the approximate solution is possible"", parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(""orthogonality tolerance is too small ({0}),"" + "" solution is orthogonal to the jacobian"", orthoTolerance);
            }
        }
    }
}","public void test2424() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    levenbergMarquardtOptimizer0.checker = null;
    levenbergMarquardtOptimizer0.setMaxIterations(2145241826);
    double[][] doubleArray0 = new double[2][9];
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn((Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0, (Object) null).when(multivariateMatrixFunction0).value(any(double[].class));
    double[] doubleArray1 = new double[2];
    double[] doubleArray2 = new double[2];
    levenbergMarquardtOptimizer0.setOrthoTolerance((-0.0023295157986838455));
    doubleArray2[0] = Double.NEGATIVE_INFINITY;
    doubleArray1[0] = (double) 100;
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray1, (Object) doubleArray1, (Object) doubleArray2, (Object) doubleArray2, (Object) doubleArray1).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
    levenbergMarquardtOptimizer0.doOptimize();
    doubleArray0[0] = doubleArray1;
    levenbergMarquardtOptimizer0.setOrthoTolerance((-869.9265));
    levenbergMarquardtOptimizer0.doOptimize();
    levenbergMarquardtOptimizer0.doOptimize();
    levenbergMarquardtOptimizer0.doOptimize();
}","/**
 * {@inheritDoc}
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return new VectorialPointValuePair(point, objective);
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            // tests for convergence.
            // we use the vectorial convergence checker
            // we use the Levenberg-Marquardt specific convergence parameters
            if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                return new VectorialPointValuePair(point, objective);
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(""cost relative tolerance is too small ({0}),"" + "" no further reduction in the"" + "" sum of squares is possible"", costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(""parameters relative tolerance is too small"" + "" ({0}), no further improvement in"" + "" the approximate solution is possible"", parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(""orthogonality tolerance is too small ({0}),"" + "" solution is orthogonal to the jacobian"", orthoTolerance);
            }
        }
    }
}","public void test2525() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    levenbergMarquardtOptimizer0.checker = null;
    double[][] doubleArray0 = new double[2][9];
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn((Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0).when(multivariateMatrixFunction0).value(any(double[].class));
    double[] doubleArray1 = new double[2];
    double[] doubleArray2 = new double[2];
    levenbergMarquardtOptimizer0.setOrthoTolerance(0.25);
    doubleArray2[0] = 0.25;
    doubleArray1[0] = (double) 100;
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray1, (Object) doubleArray1, (Object) doubleArray2, (Object) doubleArray2, (Object) null).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
    levenbergMarquardtOptimizer0.doOptimize();
    doubleArray0[0] = doubleArray1;
    levenbergMarquardtOptimizer0.setOrthoTolerance((-869.9265));
    levenbergMarquardtOptimizer0.doOptimize();
}","/**
 * {@inheritDoc}
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return new VectorialPointValuePair(point, objective);
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            // tests for convergence.
            // we use the vectorial convergence checker
            // we use the Levenberg-Marquardt specific convergence parameters
            if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                return new VectorialPointValuePair(point, objective);
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(""cost relative tolerance is too small ({0}),"" + "" no further reduction in the"" + "" sum of squares is possible"", costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(""parameters relative tolerance is too small"" + "" ({0}), no further improvement in"" + "" the approximate solution is possible"", parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(""orthogonality tolerance is too small ({0}),"" + "" solution is orthogonal to the jacobian"", orthoTolerance);
            }
        }
    }
}","public void test2626() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    levenbergMarquardtOptimizer0.checker = null;
    double[][] doubleArray0 = new double[2][9];
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn((Object) doubleArray0, (Object) doubleArray0, (Object) doubleArray0).when(multivariateMatrixFunction0).value(any(double[].class));
    double[] doubleArray1 = new double[2];
    double[] doubleArray2 = new double[2];
    levenbergMarquardtOptimizer0.setOrthoTolerance(0.25);
    doubleArray2[0] = 0.25;
    doubleArray1[0] = (double) 100;
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray1, (Object) doubleArray1, (Object) doubleArray2, (Object) doubleArray2, (Object) doubleArray1).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
    levenbergMarquardtOptimizer0.doOptimize();
    doubleArray0[0] = doubleArray1;
    levenbergMarquardtOptimizer0.setOrthoTolerance((-869.9265));
    levenbergMarquardtOptimizer0.doOptimize();
}","/**
 * {@inheritDoc}
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return new VectorialPointValuePair(point, objective);
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            // tests for convergence.
            // we use the vectorial convergence checker
            // we use the Levenberg-Marquardt specific convergence parameters
            if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                return new VectorialPointValuePair(point, objective);
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(""cost relative tolerance is too small ({0}),"" + "" no further reduction in the"" + "" sum of squares is possible"", costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(""parameters relative tolerance is too small"" + "" ({0}), no further improvement in"" + "" the approximate solution is possible"", parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(""orthogonality tolerance is too small ({0}),"" + "" solution is orthogonal to the jacobian"", orthoTolerance);
            }
        }
    }
}","public void test2727() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    levenbergMarquardtOptimizer0.checker = null;
    levenbergMarquardtOptimizer0.setMaxIterations(2145241826);
    double[] doubleArray0 = new double[7];
    doubleArray0[0] = (double) 2145241826;
    doubleArray0[1] = (double) 2145241826;
    doubleArray0[2] = (double) 100;
    doubleArray0[3] = (double) 2145241826;
    doubleArray0[4] = (double) 100;
    doubleArray0[5] = (double) 2145241826;
    doubleArray0[6] = (double) 100;
    levenbergMarquardtOptimizer0.residualsWeights = doubleArray0;
    double[][] doubleArray1 = new double[2][9];
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn((Object) doubleArray1, (Object) doubleArray1, (Object) doubleArray1).when(multivariateMatrixFunction0).value(any(double[].class));
    double[] doubleArray2 = new double[2];
    double[] doubleArray3 = new double[2];
    levenbergMarquardtOptimizer0.setOrthoTolerance((-0.0023295157986838455));
    doubleArray3[0] = (double) 2145241826;
    levenbergMarquardtOptimizer0.setMaxIterations(2145241826);
    doubleArray2[0] = (double) 100;
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray2, (Object) doubleArray2, (Object) doubleArray3, (Object) doubleArray3, (Object) doubleArray2).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray2, doubleArray2, doubleArray2);
    levenbergMarquardtOptimizer0.doOptimize();
    doubleArray1[0] = doubleArray2;
    levenbergMarquardtOptimizer0.setOrthoTolerance((-869.9265));
    levenbergMarquardtOptimizer0.doOptimize();
}","/**
 * {@inheritDoc}
 */"
