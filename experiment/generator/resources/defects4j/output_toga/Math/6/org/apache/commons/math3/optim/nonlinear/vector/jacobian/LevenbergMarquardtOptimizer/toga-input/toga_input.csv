focal_method,test_prefix,docstring
"public LevenbergMarquardtOptimizer(ConvergenceChecker<PointVectorValuePair> checker) {
    this(100, checker, 1e-10, 1e-10, 1e-10, Precision.SAFE_MIN);
}","public void test00() throws Throwable {
    SimplePointChecker<PointVectorValuePair> simplePointChecker0 = new SimplePointChecker<PointVectorValuePair>((-1603.965), (-1603.965));
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer(simplePointChecker0);
}","/**
 * Constructor that allows the specification of a custom convergence
 * checker.
 * Note that all the usual convergence checks will be <em>disabled</em>.
 * The default values for the algorithm settings are:
 * <ul>
 *  <li>Initial step bound factor: 100</li>
 *  <li>Cost relative tolerance: 1e-10</li>
 *  <li>Parameters relative tolerance: 1e-10</li>
 *  <li>Orthogonality tolerance: 1e-10</li>
 *  <li>QR ranking threshold: {@link Precision#SAFE_MIN}</li>
 * </ul>
 *
 * @param checker Convergence checker.
 */"
"@Override
protected PointVectorValuePair doOptimize() {
    checkParameters();
    // Number of observed data.
    final int nR = getTarget().length;
    final double[] currentPoint = getStartPoint();
    // Number of parameters.
    final int nC = currentPoint.length;
    // arrays shared with the other private methods
    solvedCols = FastMath.min(nR, nC);
    diagR = new double[nC];
    jacNorm = new double[nC];
    beta = new double[nC];
    permutation = new int[nC];
    lmDir = new double[nC];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[nC];
    double[] oldX = new double[nC];
    double[] oldRes = new double[nR];
    double[] oldObj = new double[nR];
    double[] qtf = new double[nR];
    double[] work1 = new double[nC];
    double[] work2 = new double[nC];
    double[] work3 = new double[nC];
    final RealMatrix weightMatrixSqrt = getWeightSquareRoot();
    // Evaluate the function at the starting point and calculate its norm.
    double[] currentObjective = computeObjectiveValue(currentPoint);
    double[] currentResiduals = computeResiduals(currentObjective);
    PointVectorValuePair current = new PointVectorValuePair(currentPoint, currentObjective);
    double currentCost = computeCost(currentResiduals);
    // Outer loop.
    lmPar = 0;
    boolean firstIteration = true;
    int iter = 0;
    final ConvergenceChecker<PointVectorValuePair> checker = getConvergenceChecker();
    while (true) {
        ++iter;
        final PointVectorValuePair previous = current;
        // QR decomposition of the jacobian matrix
        qrDecomposition(computeWeightedJacobian(currentPoint));
        weightedResidual = weightMatrixSqrt.operate(currentResiduals);
        for (int i = 0; i < nR; i++) {
            qtf[i] = weightedResidual[i];
        }
        // compute Qt.res
        qTy(qtf);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            weightedJacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < nC; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * currentPoint[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = FastMath.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (currentCost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += weightedJacobian[i][pj] * qtf[i];
                    }
                    maxCosine = FastMath.max(maxCosine, FastMath.abs(sum) / (s * currentCost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // Convergence has been reached.
            setCost(currentCost);
            return current;
        }
        // rescale if necessary
        for (int j = 0; j < nC; ++j) {
            diag[j] = FastMath.max(diag[j], jacNorm[j]);
        }
        // Inner loop.
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = currentPoint[pj];
            }
            final double previousCost = currentCost;
            double[] tmpVec = weightedResidual;
            weightedResidual = oldRes;
            oldRes = tmpVec;
            tmpVec = currentObjective;
            currentObjective = oldObj;
            oldObj = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(qtf, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                currentPoint[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = FastMath.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = FastMath.min(delta, lmNorm);
            }
            // Evaluate the function at x + p and calculate its norm.
            currentObjective = computeObjectiveValue(currentPoint);
            currentResiduals = computeResiduals(currentObjective);
            current = new PointVectorValuePair(currentPoint, currentObjective);
            currentCost = computeCost(currentResiduals);
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * currentCost < previousCost) {
                double r = currentCost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += weightedJacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * currentCost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * FastMath.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < nC; ++k) {
                    double xK = diag[k] * currentPoint[k];
                    xNorm += xK * xK;
                }
                xNorm = FastMath.sqrt(xNorm);
                // tests for convergence.
                if (checker != null) {
                    // we use the vectorial convergence checker
                    if (checker.converged(iter, previous, current)) {
                        setCost(currentCost);
                        return current;
                    }
                }
            } else {
                // failed iteration, reset the previous values
                currentCost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    currentPoint[pj] = oldX[pj];
                }
                tmpVec = weightedResidual;
                weightedResidual = oldRes;
                oldRes = tmpVec;
                tmpVec = currentObjective;
                currentObjective = oldObj;
                oldObj = tmpVec;
                // Reset ""current"" to previous values.
                current = new PointVectorValuePair(currentPoint, currentObjective);
            }
            // Default convergence criteria.
            if ((FastMath.abs(actRed) <= costRelativeTolerance && preRed <= costRelativeTolerance && ratio <= 2.0) || delta <= parRelativeTolerance * xNorm) {
                setCost(currentCost);
                return current;
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((FastMath.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new ConvergenceException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE, costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new ConvergenceException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE, parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new ConvergenceException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE, orthoTolerance);
            }
        }
    }
}","public void test11() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    // Undeclared exception!
    try {
        levenbergMarquardtOptimizer0.doOptimize();
        fail(""Expecting exception: NullPointerException"");
    } catch (NullPointerException e) {
        //
        // no message in exception (getMessage() returned null)
        //
        verifyException(""org.apache.commons.math3.optim.nonlinear.vector.MultivariateVectorOptimizer"", e);
    }
}","/**
 * {@inheritDoc}
 */"
"public LevenbergMarquardtOptimizer(double costRelativeTolerance, double parRelativeTolerance, double orthoTolerance) {
    this(100, costRelativeTolerance, parRelativeTolerance, orthoTolerance, Precision.SAFE_MIN);
}","public void test22() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer(1.0E-4, 1.0E-4, 1.0E-4);
}","/**
 * Build an optimizer for least squares problems with default values
 * for some of the tuning parameters (see the {@link
 * #LevenbergMarquardtOptimizer(double,double,double,double,double)
 * other contructor}.
 * The default values for the algorithm settings are:
 * <ul>
 *  <li>Initial step bound factor}: 100</li>
 *  <li>QR ranking threshold}: {@link Precision#SAFE_MIN}</li>
 * </ul>
 *
 * @param costRelativeTolerance Desired relative error in the sum of
 * squares.
 * @param parRelativeTolerance Desired relative error in the approximate
 * solution parameters.
 * @param orthoTolerance Desired max cosine on the orthogonality between
 * the function vector and the columns of the Jacobian.
 */"
