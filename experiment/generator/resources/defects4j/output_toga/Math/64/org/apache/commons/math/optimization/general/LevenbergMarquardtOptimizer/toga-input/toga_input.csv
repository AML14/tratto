focal_method,test_prefix,docstring
"public VectorialPointValuePair optimize(final DifferentiableMultivariateVectorialFunction f, final double[] target, final double[] weights, final double[] startPoint) throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    if (target.length != weights.length) {
        throw new OptimizationException(LocalizedFormats.DIMENSIONS_MISMATCH_SIMPLE, target.length, weights.length);
    }
    // reset counters
    iterations = 0;
    objectiveEvaluations = 0;
    jacobianEvaluations = 0;
    // store least squares problem characteristics
    function = f;
    jF = f.jacobian();
    targetValues = target.clone();
    residualsWeights = weights.clone();
    this.point = startPoint.clone();
    this.residuals = new double[target.length];
    // arrays shared with the other private methods
    rows = target.length;
    cols = point.length;
    jacobian = new double[rows][cols];
    cost = Double.POSITIVE_INFINITY;
    return doOptimize();
}","public void test000() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    double[][] doubleArray0 = new double[1][6];
    double[] doubleArray1 = new double[1];
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn(doubleArray0).when(multivariateMatrixFunction0).value(any(double[].class));
    doubleArray1[0] = (-94.83151985);
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn(doubleArray1).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    try {
        levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
        fail(""Expecting exception: Exception"");
    } catch (Exception e) {
        //
        // unable to perform Q.R decomposition on the 1x1 jacobian matrix
        //
        verifyException(""org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer"", e);
    }
}","/**
 * {@inheritDoc}
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    VectorialPointValuePair current = new VectorialPointValuePair(point, objective);
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        VectorialPointValuePair previous = current;
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return current;
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            current = new VectorialPointValuePair(point, objective);
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
                // tests for convergence.
                // we use the vectorial convergence checker
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            if (checker == null) {
                if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                    return current;
                }
            } else {
                if (checker.converged(getIterations(), previous, current)) {
                    return current;
                }
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE, costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE, parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE, orthoTolerance);
            }
        }
    }
}","public void test011() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    levenbergMarquardtOptimizer0.cols = 49;
    // Undeclared exception!
    try {
        levenbergMarquardtOptimizer0.doOptimize();
        fail(""Expecting exception: NullPointerException"");
    } catch (NullPointerException e) {
        //
        // no message in exception (getMessage() returned null)
        //
        verifyException(""org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer"", e);
    }
}","/**
 * {@inheritDoc}
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    VectorialPointValuePair current = new VectorialPointValuePair(point, objective);
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        VectorialPointValuePair previous = current;
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return current;
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            current = new VectorialPointValuePair(point, objective);
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
                // tests for convergence.
                // we use the vectorial convergence checker
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            if (checker == null) {
                if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                    return current;
                }
            } else {
                if (checker.converged(getIterations(), previous, current)) {
                    return current;
                }
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE, costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE, parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE, orthoTolerance);
            }
        }
    }
}","public void test022() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    double[][] doubleArray0 = new double[1][6];
    double[] doubleArray1 = new double[1];
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn(doubleArray0).when(multivariateMatrixFunction0).value(any(double[].class));
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray1, (Object) null).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
    // Undeclared exception!
    try {
        levenbergMarquardtOptimizer0.doOptimize();
        fail(""Expecting exception: NullPointerException"");
    } catch (NullPointerException e) {
        //
        // no message in exception (getMessage() returned null)
        //
        verifyException(""org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer"", e);
    }
}","/**
 * {@inheritDoc}
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    VectorialPointValuePair current = new VectorialPointValuePair(point, objective);
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        VectorialPointValuePair previous = current;
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return current;
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            current = new VectorialPointValuePair(point, objective);
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
                // tests for convergence.
                // we use the vectorial convergence checker
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            if (checker == null) {
                if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                    return current;
                }
            } else {
                if (checker.converged(getIterations(), previous, current)) {
                    return current;
                }
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE, costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE, parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE, orthoTolerance);
            }
        }
    }
}","public void test033() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    double[][] doubleArray0 = new double[1][6];
    double[] doubleArray1 = new double[1];
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn(doubleArray0).when(multivariateMatrixFunction0).value(any(double[].class));
    double[] doubleArray2 = new double[0];
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray1, (Object) doubleArray2).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
    try {
        levenbergMarquardtOptimizer0.doOptimize();
        fail(""Expecting exception: Exception"");
    } catch (Exception e) {
        //
        // dimensions mismatch 0 != 1
        //
        verifyException(""org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer"", e);
    }
}","/**
 * {@inheritDoc}
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    VectorialPointValuePair current = new VectorialPointValuePair(point, objective);
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        VectorialPointValuePair previous = current;
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return current;
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            current = new VectorialPointValuePair(point, objective);
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
                // tests for convergence.
                // we use the vectorial convergence checker
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            if (checker == null) {
                if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                    return current;
                }
            } else {
                if (checker.converged(getIterations(), previous, current)) {
                    return current;
                }
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE, costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE, parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE, orthoTolerance);
            }
        }
    }
}","public void test044() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    double[][] doubleArray0 = new double[2][6];
    double[] doubleArray1 = new double[2];
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn(doubleArray0).when(multivariateMatrixFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.setMaxIterations(1);
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray1, (Object) doubleArray1).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
    try {
        levenbergMarquardtOptimizer0.doOptimize();
        fail(""Expecting exception: Exception"");
    } catch (Exception e) {
        //
        // maximal number of iterations (1) exceeded
        //
        verifyException(""org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer"", e);
    }
}","/**
 * {@inheritDoc}
 */"
"@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    VectorialPointValuePair current = new VectorialPointValuePair(point, objective);
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        VectorialPointValuePair previous = current;
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // now we don't need Q anymore,
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return current;
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            current = new VectorialPointValuePair(point, objective);
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // compute the scaled predicted reduction
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
                // tests for convergence.
                // we use the vectorial convergence checker
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            if (checker == null) {
                if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                    return current;
                }
            } else {
                if (checker.converged(getIterations(), previous, current)) {
                    return current;
                }
            }
            // tests for termination and stringent tolerances
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE, costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE, parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE, orthoTolerance);
            }
        }
    }
}","public void test055() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    levenbergMarquardtOptimizer0.rows = (-1);
    // Undeclared exception!
    try {
        levenbergMarquardtOptimizer0.doOptimize();
        fail(""Expecting exception: NegativeArraySizeException"");
    } catch (NegativeArraySizeException e) {
        //
        // no message in exception (getMessage() returned null)
        //
        verifyException(""org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer"", e);
    }
}","/**
 * {@inheritDoc}
 */"
"public int getMaxIterations() {
    return maxIterations;
}","public void test066() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    levenbergMarquardtOptimizer0.setParRelativeTolerance(1637.44);
    assertEquals(1000, levenbergMarquardtOptimizer0.getMaxIterations());
}","/**
 * {@inheritDoc}
 */"
"public VectorialPointValuePair optimize(final DifferentiableMultivariateVectorialFunction f, final double[] target, final double[] weights, final double[] startPoint) throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    if (target.length != weights.length) {
        throw new OptimizationException(LocalizedFormats.DIMENSIONS_MISMATCH_SIMPLE, target.length, weights.length);
    }
    // reset counters
    iterations = 0;
    objectiveEvaluations = 0;
    jacobianEvaluations = 0;
    // store least squares problem characteristics
    function = f;
    jF = f.jacobian();
    targetValues = target.clone();
    residualsWeights = weights.clone();
    this.point = startPoint.clone();
    this.residuals = new double[target.length];
    // arrays shared with the other private methods
    rows = target.length;
    cols = point.length;
    jacobian = new double[rows][cols];
    cost = Double.POSITIVE_INFINITY;
    return doOptimize();
}","public void test077() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    double[][] doubleArray0 = new double[2][6];
    double[] doubleArray1 = new double[2];
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn(doubleArray0).when(multivariateMatrixFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.setQRRankingThreshold((-3473.304238));
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn(doubleArray1).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    try {
        levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
        fail(""Expecting exception: Exception"");
    } catch (Exception e) {
        //
        // unable to perform Q.R decomposition on the 2x2 jacobian matrix
        //
        verifyException(""org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer"", e);
    }
}","/**
 * {@inheritDoc}
 */"
"public VectorialPointValuePair optimize(final DifferentiableMultivariateVectorialFunction f, final double[] target, final double[] weights, final double[] startPoint) throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    if (target.length != weights.length) {
        throw new OptimizationException(LocalizedFormats.DIMENSIONS_MISMATCH_SIMPLE, target.length, weights.length);
    }
    // reset counters
    iterations = 0;
    objectiveEvaluations = 0;
    jacobianEvaluations = 0;
    // store least squares problem characteristics
    function = f;
    jF = f.jacobian();
    targetValues = target.clone();
    residualsWeights = weights.clone();
    this.point = startPoint.clone();
    this.residuals = new double[target.length];
    // arrays shared with the other private methods
    rows = target.length;
    cols = point.length;
    jacobian = new double[rows][cols];
    cost = Double.POSITIVE_INFINITY;
    return doOptimize();
}","public void test088() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    double[][] doubleArray0 = new double[1][6];
    double[] doubleArray1 = new double[1];
    levenbergMarquardtOptimizer0.setInitialStepBoundFactor(Double.NEGATIVE_INFINITY);
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn(doubleArray0).when(multivariateMatrixFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.setOrthoTolerance(Double.NEGATIVE_INFINITY);
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray1, (Object) doubleArray1).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    try {
        levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
        fail(""Expecting exception: Exception"");
    } catch (Exception e) {
        //
        // orthogonality tolerance is too small (-\u221E), solution is orthogonal to the jacobian
        //
        verifyException(""org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer"", e);
    }
}","/**
 * {@inheritDoc}
 */"
"public VectorialPointValuePair optimize(final DifferentiableMultivariateVectorialFunction f, final double[] target, final double[] weights, final double[] startPoint) throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    if (target.length != weights.length) {
        throw new OptimizationException(LocalizedFormats.DIMENSIONS_MISMATCH_SIMPLE, target.length, weights.length);
    }
    // reset counters
    iterations = 0;
    objectiveEvaluations = 0;
    jacobianEvaluations = 0;
    // store least squares problem characteristics
    function = f;
    jF = f.jacobian();
    targetValues = target.clone();
    residualsWeights = weights.clone();
    this.point = startPoint.clone();
    this.residuals = new double[target.length];
    // arrays shared with the other private methods
    rows = target.length;
    cols = point.length;
    jacobian = new double[rows][cols];
    cost = Double.POSITIVE_INFINITY;
    return doOptimize();
}","public void test099() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    double[][] doubleArray0 = new double[1][6];
    double[] doubleArray1 = new double[1];
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn(doubleArray0).when(multivariateMatrixFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.setOrthoTolerance((-3473.304238));
    levenbergMarquardtOptimizer0.setInitialStepBoundFactor((-2491.571243063269));
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray1, (Object) null).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    // Undeclared exception!
    try {
        levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
        fail(""Expecting exception: NullPointerException"");
    } catch (NullPointerException e) {
        //
        // no message in exception (getMessage() returned null)
        //
        verifyException(""org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer"", e);
    }
}","/**
 * {@inheritDoc}
 */"
"public int getEvaluations() {
    return objectiveEvaluations;
}","public void test1010() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    double[][] doubleArray0 = new double[1][6];
    double[] doubleArray1 = new double[1];
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn(doubleArray0).when(multivariateMatrixFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.setCostRelativeTolerance(100);
    levenbergMarquardtOptimizer0.setOrthoTolerance((-1008.4756371066549));
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray1, (Object) doubleArray1).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
    assertEquals(2, levenbergMarquardtOptimizer0.getEvaluations());
}","/**
 * {@inheritDoc}
 */"
"public VectorialPointValuePair optimize(final DifferentiableMultivariateVectorialFunction f, final double[] target, final double[] weights, final double[] startPoint) throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    if (target.length != weights.length) {
        throw new OptimizationException(LocalizedFormats.DIMENSIONS_MISMATCH_SIMPLE, target.length, weights.length);
    }
    // reset counters
    iterations = 0;
    objectiveEvaluations = 0;
    jacobianEvaluations = 0;
    // store least squares problem characteristics
    function = f;
    jF = f.jacobian();
    targetValues = target.clone();
    residualsWeights = weights.clone();
    this.point = startPoint.clone();
    this.residuals = new double[target.length];
    // arrays shared with the other private methods
    rows = target.length;
    cols = point.length;
    jacobian = new double[rows][cols];
    cost = Double.POSITIVE_INFINITY;
    return doOptimize();
}","public void test1111() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    double[][] doubleArray0 = new double[1][6];
    double[] doubleArray1 = new double[1];
    SimpleVectorialValueChecker simpleVectorialValueChecker0 = new SimpleVectorialValueChecker((-58.597104784), (-58.597104784));
    levenbergMarquardtOptimizer0.setConvergenceChecker(simpleVectorialValueChecker0);
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn(doubleArray0).when(multivariateMatrixFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.setOrthoTolerance(Double.NEGATIVE_INFINITY);
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray1, (Object) null).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    // Undeclared exception!
    try {
        levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
        fail(""Expecting exception: NullPointerException"");
    } catch (NullPointerException e) {
        //
        // no message in exception (getMessage() returned null)
        //
        verifyException(""org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer"", e);
    }
}","/**
 * {@inheritDoc}
 */"
"public VectorialPointValuePair optimize(final DifferentiableMultivariateVectorialFunction f, final double[] target, final double[] weights, final double[] startPoint) throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    if (target.length != weights.length) {
        throw new OptimizationException(LocalizedFormats.DIMENSIONS_MISMATCH_SIMPLE, target.length, weights.length);
    }
    // reset counters
    iterations = 0;
    objectiveEvaluations = 0;
    jacobianEvaluations = 0;
    // store least squares problem characteristics
    function = f;
    jF = f.jacobian();
    targetValues = target.clone();
    residualsWeights = weights.clone();
    this.point = startPoint.clone();
    this.residuals = new double[target.length];
    // arrays shared with the other private methods
    rows = target.length;
    cols = point.length;
    jacobian = new double[rows][cols];
    cost = Double.POSITIVE_INFINITY;
    return doOptimize();
}","public void test1212() throws Throwable {
    LevenbergMarquardtOptimizer levenbergMarquardtOptimizer0 = new LevenbergMarquardtOptimizer();
    double[][] doubleArray0 = new double[1][6];
    double[] doubleArray1 = new double[1];
    MultivariateMatrixFunction multivariateMatrixFunction0 = mock(MultivariateMatrixFunction.class, new ViolatedAssumptionAnswer());
    doReturn(doubleArray0).when(multivariateMatrixFunction0).value(any(double[].class));
    levenbergMarquardtOptimizer0.setOrthoTolerance((-1008.4756371066549));
    levenbergMarquardtOptimizer0.setQRRankingThreshold((-2202.23851991449));
    DifferentiableMultivariateVectorialFunction differentiableMultivariateVectorialFunction0 = mock(DifferentiableMultivariateVectorialFunction.class, new ViolatedAssumptionAnswer());
    doReturn(multivariateMatrixFunction0).when(differentiableMultivariateVectorialFunction0).jacobian();
    doReturn((Object) doubleArray1, (Object) null).when(differentiableMultivariateVectorialFunction0).value(any(double[].class));
    // Undeclared exception!
    try {
        levenbergMarquardtOptimizer0.optimize(differentiableMultivariateVectorialFunction0, doubleArray1, doubleArray1, doubleArray1);
        fail(""Expecting exception: NullPointerException"");
    } catch (NullPointerException e) {
        //
        // no message in exception (getMessage() returned null)
        //
        verifyException(""org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer"", e);
    }
}","/**
 * {@inheritDoc}
 */"
