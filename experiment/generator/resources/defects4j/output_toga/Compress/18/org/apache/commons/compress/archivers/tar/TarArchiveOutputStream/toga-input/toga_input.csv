focal_method,test_prefix,docstring
"@Override
public void write(byte[] wBuf, int wOffset, int numToWrite) throws IOException {
    if ((currBytes + numToWrite) > currSize) {
        throw new IOException(""request to write '"" + numToWrite + ""' bytes exceeds size in header of '"" + currSize + ""' bytes for entry '"" + currName + ""'"");
        //
        // We have to deal with assembly!!!
        // The programmer can be writing little 32 byte chunks for all
        // we know, and we must assemble complete records for writing.
        // REVIEW Maybe this should be in TarBuffer? Could that help to
        // eliminate some of the buffer copying.
        //
    }
    if (assemLen > 0) {
        if ((assemLen + numToWrite) >= recordBuf.length) {
            int aLen = recordBuf.length - assemLen;
            System.arraycopy(assemBuf, 0, recordBuf, 0, assemLen);
            System.arraycopy(wBuf, wOffset, recordBuf, assemLen, aLen);
            buffer.writeRecord(recordBuf);
            currBytes += recordBuf.length;
            wOffset += aLen;
            numToWrite -= aLen;
            assemLen = 0;
        } else {
            System.arraycopy(wBuf, wOffset, assemBuf, assemLen, numToWrite);
            wOffset += numToWrite;
            assemLen += numToWrite;
            numToWrite = 0;
        }
    }
    //
    // When we get here we have EITHER:
    // o An empty ""assemble"" buffer.
    // o No bytes to write (numToWrite == 0)
    //
    while (numToWrite > 0) {
        if (numToWrite < recordBuf.length) {
            System.arraycopy(wBuf, wOffset, assemBuf, assemLen, numToWrite);
            assemLen += numToWrite;
            break;
        }
        buffer.writeRecord(wBuf, wOffset);
        int num = recordBuf.length;
        currBytes += num;
        numToWrite -= num;
        wOffset += num;
    }
}","public void test000() throws Throwable {
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream((OutputStream) null, 3);
    byte[] byteArray0 = new byte[6];
    tarArchiveOutputStream0.write(byteArray0, (int) (byte) (-1), (int) (byte) (-1));
}","/**
 * Writes bytes to the current tar archive entry. This method
 * is aware of the current entry and will throw an exception if
 * you attempt to write bytes past the length specified for the
 * current entry. The method is also (painfully) aware of the
 * record buffering required by TarBuffer, and manages buffers
 * that are not a multiple of recordsize in length, including
 * assembling records from small buffers.
 *
 * @param wBuf The buffer to write to the archive.
 * @param wOffset The offset in the buffer from which to get bytes.
 * @param numToWrite The number of bytes to write.
 * @throws IOException on error
 */"
"public void setLongFileMode(int longFileMode) {
    this.longFileMode = longFileMode;
}","public void test011() throws Throwable {
    ByteArrayOutputStream byteArrayOutputStream0 = new ByteArrayOutputStream();
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream(byteArrayOutputStream0, 2958, ""org.apache.commons.compress.archivers.zip.Zip64ExtendedInformationExtraField"");
    tarArchiveOutputStream0.setLongFileMode(898);
}","/**
 * Set the long file mode.
 * This can be LONGFILE_ERROR(0), LONGFILE_TRUNCATE(1) or LONGFILE_GNU(2).
 * This specifies the treatment of long file names (names >= TarConstants.NAMELEN).
 * Default is LONGFILE_ERROR.
 * @param longFileMode the mode to use
 */"
"@Deprecated
@Override
public int getCount() {
    return (int) getBytesWritten();
}","public void test022() throws Throwable {
    ByteArrayOutputStream byteArrayOutputStream0 = new ByteArrayOutputStream();
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream(byteArrayOutputStream0, 2958, ""org.apache.commons.compress.archivers.zip.Zip64ExtendedInformationExtraField"");
    tarArchiveOutputStream0.finish();
    tarArchiveOutputStream0.getCount();
}",""
"@Override
public ArchiveEntry createArchiveEntry(File inputFile, String entryName) throws IOException {
    if (finished) {
        throw new IOException(""Stream has already been finished"");
    }
    return new TarArchiveEntry(inputFile, entryName);
}","public void test033() throws Throwable {
    File file0 = MockFile.createTempFile(""XJ_"", ""XJ_"");
    MockFileOutputStream mockFileOutputStream0 = new MockFileOutputStream(file0, false);
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream(mockFileOutputStream0, ""XJ_"");
    tarArchiveOutputStream0.createArchiveEntry(file0, """");
}","/**
 * {@inheritDoc}
 */"
"void writePaxHeaders(String entryName, Map<String, String> headers) throws IOException {
    String name = ""./PaxHeaders.X/"" + stripTo7Bits(entryName);
    // TarEntry's constructor would think this is a directory
    // and not allow any data to be written
    if (name.length() >= TarConstants.NAMELEN) {
        name = name.substring(0, TarConstants.NAMELEN - 1);
    }
    TarArchiveEntry pex = new TarArchiveEntry(name, TarConstants.LF_PAX_EXTENDED_HEADER_LC);
    StringWriter w = new StringWriter();
    for (Map.Entry<String, String> h : headers.entrySet()) {
        String key = h.getKey();
        String value = h.getValue();
        int len = key.length() + value.length() + 3 + /* blank, equals and newline */
        2;
        String line = len + "" "" + key + ""="" + value + ""\n"";
        int actualLength = line.getBytes(CharsetNames.UTF_8).length;
        while (len != actualLength) {
            // Adjust for cases where length < 10 or > 100
            // or where UTF-8 encoding isn't a single octet
            // per character.
            // Must be in loop as size may go from 99 to 100 in
            // first pass so we'd need a second.
            len = actualLength;
            line = len + "" "" + key + ""="" + value + ""\n"";
            actualLength = line.getBytes(CharsetNames.UTF_8).length;
        }
        w.write(line);
    }
    byte[] data = w.toString().getBytes(CharsetNames.UTF_8);
    pex.setSize(data.length);
    putArchiveEntry(pex);
    write(data);
    closeArchiveEntry();
}","public void test044() throws Throwable {
    File file0 = MockFile.createTempFile(""XJ_"", ""XJ_"");
    MockFileOutputStream mockFileOutputStream0 = new MockFileOutputStream(file0, false);
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream(mockFileOutputStream0, ""XJ_"");
    Map<String, String> map0 = ZoneId.SHORT_IDS;
    // Undeclared exception!
    try {
        tarArchiveOutputStream0.writePaxHeaders((String) null, map0);
        fail(""Expecting exception: NullPointerException"");
    } catch (NullPointerException e) {
        //
        // no message in exception (getMessage() returned null)
        //
        verifyException(""org.apache.commons.compress.archivers.tar.TarArchiveOutputStream"", e);
    }
}","/**
 * Writes a PAX extended header with the given map as contents.
 * @since 1.4
 */"
"void writePaxHeaders(String entryName, Map<String, String> headers) throws IOException {
    String name = ""./PaxHeaders.X/"" + stripTo7Bits(entryName);
    // TarEntry's constructor would think this is a directory
    // and not allow any data to be written
    if (name.length() >= TarConstants.NAMELEN) {
        name = name.substring(0, TarConstants.NAMELEN - 1);
    }
    TarArchiveEntry pex = new TarArchiveEntry(name, TarConstants.LF_PAX_EXTENDED_HEADER_LC);
    StringWriter w = new StringWriter();
    for (Map.Entry<String, String> h : headers.entrySet()) {
        String key = h.getKey();
        String value = h.getValue();
        int len = key.length() + value.length() + 3 + /* blank, equals and newline */
        2;
        String line = len + "" "" + key + ""="" + value + ""\n"";
        int actualLength = line.getBytes(CharsetNames.UTF_8).length;
        while (len != actualLength) {
            // Adjust for cases where length < 10 or > 100
            // or where UTF-8 encoding isn't a single octet
            // per character.
            // Must be in loop as size may go from 99 to 100 in
            // first pass so we'd need a second.
            len = actualLength;
            line = len + "" "" + key + ""="" + value + ""\n"";
            actualLength = line.getBytes(CharsetNames.UTF_8).length;
        }
        w.write(line);
    }
    byte[] data = w.toString().getBytes(CharsetNames.UTF_8);
    pex.setSize(data.length);
    putArchiveEntry(pex);
    write(data);
    closeArchiveEntry();
}","public void test055() throws Throwable {
    MockFile mockFile0 = new MockFile(""wIp{s2qfiJD2"");
    MockPrintStream mockPrintStream0 = new MockPrintStream(mockFile0);
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream(mockPrintStream0, (byte) 48, 193);
    Map<String, String> map0 = ZoneId.SHORT_IDS;
    // Undeclared exception!
    try {
        tarArchiveOutputStream0.writePaxHeaders("""", map0);
        fail(""Expecting exception: ArrayIndexOutOfBoundsException"");
    } catch (ArrayIndexOutOfBoundsException e) {
        //
        // 193
        //
        verifyException(""org.apache.commons.compress.archivers.tar.TarUtils"", e);
    }
}","/**
 * Writes a PAX extended header with the given map as contents.
 * @since 1.4
 */"
"@Override
public void flush() throws IOException {
    out.flush();
}","public void test066() throws Throwable {
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream((OutputStream) null, 249);
    // Undeclared exception!
    try {
        tarArchiveOutputStream0.flush();
        fail(""Expecting exception: NullPointerException"");
    } catch (NullPointerException e) {
        //
        // no message in exception (getMessage() returned null)
        //
        verifyException(""java.io.FilterOutputStream"", e);
    }
}",""
"@Override
public void finish() throws IOException {
    if (finished) {
        throw new IOException(""This archive has already been finished"");
    }
    if (haveUnclosedEntry) {
        throw new IOException(""This archives contains unclosed entries."");
    }
    writeEOFRecord();
    writeEOFRecord();
    buffer.flushBlock();
    finished = true;
}","public void test077() throws Throwable {
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream((OutputStream) null, 2241);
    // Undeclared exception!
    try {
        tarArchiveOutputStream0.finish();
        fail(""Expecting exception: NullPointerException"");
    } catch (NullPointerException e) {
        //
        // no message in exception (getMessage() returned null)
        //
        verifyException(""org.apache.commons.compress.utils.CountingOutputStream"", e);
    }
}","/**
 * Ends the TAR archive without closing the underlying OutputStream.
 *
 * An archive consists of a series of file entries terminated by an
 * end-of-archive entry, which consists of two 512 blocks of zero bytes.
 * POSIX.1 requires two EOF records, like some other implementations.
 *
 * @throws IOException on error
 */"
"@Override
public void finish() throws IOException {
    if (finished) {
        throw new IOException(""This archive has already been finished"");
    }
    if (haveUnclosedEntry) {
        throw new IOException(""This archives contains unclosed entries."");
    }
    writeEOFRecord();
    writeEOFRecord();
    buffer.flushBlock();
    finished = true;
}","public void test088() throws Throwable {
    MockPrintStream mockPrintStream0 = new MockPrintStream(""Ejd5R|eeb^5z4*"");
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream(mockPrintStream0, 57);
    // Undeclared exception!
    try {
        tarArchiveOutputStream0.finish();
        fail(""Expecting exception: ArrayIndexOutOfBoundsException"");
    } catch (ArrayIndexOutOfBoundsException e) {
    }
}","/**
 * Ends the TAR archive without closing the underlying OutputStream.
 *
 * An archive consists of a series of file entries terminated by an
 * end-of-archive entry, which consists of two 512 blocks of zero bytes.
 * POSIX.1 requires two EOF records, like some other implementations.
 *
 * @throws IOException on error
 */"
"@Override
public void finish() throws IOException {
    if (finished) {
        throw new IOException(""This archive has already been finished"");
    }
    if (haveUnclosedEntry) {
        throw new IOException(""This archives contains unclosed entries."");
    }
    writeEOFRecord();
    writeEOFRecord();
    buffer.flushBlock();
    finished = true;
}","public void test099() throws Throwable {
    PipedOutputStream pipedOutputStream0 = new PipedOutputStream();
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream(pipedOutputStream0, 468);
    try {
        tarArchiveOutputStream0.finish();
        fail(""Expecting exception: IOException"");
    } catch (IOException e) {
        //
        // Pipe not connected
        //
        verifyException(""java.io.PipedOutputStream"", e);
    }
}","/**
 * Ends the TAR archive without closing the underlying OutputStream.
 *
 * An archive consists of a series of file entries terminated by an
 * end-of-archive entry, which consists of two 512 blocks of zero bytes.
 * POSIX.1 requires two EOF records, like some other implementations.
 *
 * @throws IOException on error
 */"
"@Override
public void close() throws IOException {
    if (!finished) {
        finish();
    }
    if (!closed) {
        buffer.close();
        out.close();
        closed = true;
    }
}","public void test1010() throws Throwable {
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream((OutputStream) null, 2241);
    // Undeclared exception!
    try {
        tarArchiveOutputStream0.close();
        fail(""Expecting exception: NullPointerException"");
    } catch (NullPointerException e) {
        //
        // no message in exception (getMessage() returned null)
        //
        verifyException(""org.apache.commons.compress.utils.CountingOutputStream"", e);
    }
}","/**
 * Closes the underlying OutputStream.
 * @throws IOException on error
 */"
"public TarArchiveOutputStream(OutputStream os, String encoding) {
    this(os, TarBuffer.DEFAULT_BLKSIZE, TarBuffer.DEFAULT_RCDSIZE, encoding);
}","public void test1111() throws Throwable {
    TarArchiveOutputStream tarArchiveOutputStream0 = null;
    try {
        tarArchiveOutputStream0 = new TarArchiveOutputStream((OutputStream) null, ""1*vz+F`<>Ky&"");
        fail(""Expecting exception: IllegalCharsetNameException"");
    } catch (IllegalCharsetNameException e) {
        //
        // 1*vz+F`<>Ky&
        //
        verifyException(""java.nio.charset.Charset"", e);
    }
}","/**
 * Constructor for TarInputStream.
 * @param os the output stream to use
 * @param encoding name of the encoding to use for file names
 * @since Commons Compress 1.4
 */"
"public TarArchiveOutputStream(OutputStream os, int blockSize, String encoding) {
    this(os, blockSize, TarBuffer.DEFAULT_RCDSIZE, encoding);
}","public void test1212() throws Throwable {
    TarArchiveOutputStream tarArchiveOutputStream0 = null;
    try {
        tarArchiveOutputStream0 = new TarArchiveOutputStream((OutputStream) null, 2028, ""#"");
        fail(""Expecting exception: IllegalCharsetNameException"");
    } catch (IllegalCharsetNameException e) {
        //
        // #
        //
        verifyException(""java.nio.charset.Charset"", e);
    }
}","/**
 * Constructor for TarInputStream.
 * @param os the output stream to use
 * @param blockSize the block size to use
 * @param encoding name of the encoding to use for file names
 * @since Commons Compress 1.4
 */"
"public TarArchiveOutputStream(OutputStream os, int blockSize, int recordSize, String encoding) {
    out = new CountingOutputStream(os);
    this.encoding = ZipEncodingHelper.getZipEncoding(encoding);
    this.buffer = new TarBuffer(out, blockSize, recordSize);
    this.assemLen = 0;
    this.assemBuf = new byte[recordSize];
    this.recordBuf = new byte[recordSize];
}","public void test1313() throws Throwable {
    MockFileOutputStream mockFileOutputStream0 = new MockFileOutputStream("".m7{au(E"", true);
    TarArchiveOutputStream tarArchiveOutputStream0 = null;
    try {
        tarArchiveOutputStream0 = new TarArchiveOutputStream(mockFileOutputStream0, 3, 0, """");
        fail(""Expecting exception: IllegalCharsetNameException"");
    } catch (IllegalCharsetNameException e) {
        //
        //
        //
        verifyException(""java.nio.charset.Charset"", e);
    }
}","/**
 * Constructor for TarInputStream.
 * @param os the output stream to use
 * @param blockSize the block size to use
 * @param recordSize the record size to use
 * @param encoding name of the encoding to use for file names
 * @since Commons Compress 1.4
 */"
"public TarArchiveOutputStream(OutputStream os, int blockSize, int recordSize, String encoding) {
    out = new CountingOutputStream(os);
    this.encoding = ZipEncodingHelper.getZipEncoding(encoding);
    this.buffer = new TarBuffer(out, blockSize, recordSize);
    this.assemLen = 0;
    this.assemBuf = new byte[recordSize];
    this.recordBuf = new byte[recordSize];
}","public void test1414() throws Throwable {
    MockFileOutputStream mockFileOutputStream0 = new MockFileOutputStream(""size"");
    TarArchiveOutputStream tarArchiveOutputStream0 = null;
    try {
        tarArchiveOutputStream0 = new TarArchiveOutputStream(mockFileOutputStream0, (-1823), (-192), ""size"");
        fail(""Expecting exception: NegativeArraySizeException"");
    } catch (NegativeArraySizeException e) {
        //
        // no message in exception (getMessage() returned null)
        //
        verifyException(""org.apache.commons.compress.archivers.tar.TarBuffer"", e);
    }
}","/**
 * Constructor for TarInputStream.
 * @param os the output stream to use
 * @param blockSize the block size to use
 * @param recordSize the record size to use
 * @param encoding name of the encoding to use for file names
 * @since Commons Compress 1.4
 */"
"public TarArchiveOutputStream(OutputStream os, int blockSize, int recordSize, String encoding) {
    out = new CountingOutputStream(os);
    this.encoding = ZipEncodingHelper.getZipEncoding(encoding);
    this.buffer = new TarBuffer(out, blockSize, recordSize);
    this.assemLen = 0;
    this.assemBuf = new byte[recordSize];
    this.recordBuf = new byte[recordSize];
}","public void test1515() throws Throwable {
    File file0 = MockFile.createTempFile(""])u3J8n5D`"", ""])u3J8n5D`"");
    MockFileOutputStream mockFileOutputStream0 = new MockFileOutputStream(file0, true);
    TarArchiveOutputStream tarArchiveOutputStream0 = null;
    try {
        tarArchiveOutputStream0 = new TarArchiveOutputStream(mockFileOutputStream0, 0, 0, (String) null);
        fail(""Expecting exception: ArithmeticException"");
    } catch (ArithmeticException e) {
        //
        // / by zero
        //
        verifyException(""org.apache.commons.compress.archivers.tar.TarBuffer"", e);
    }
}","/**
 * Constructor for TarInputStream.
 * @param os the output stream to use
 * @param blockSize the block size to use
 * @param recordSize the record size to use
 * @param encoding name of the encoding to use for file names
 * @since Commons Compress 1.4
 */"
"public TarArchiveOutputStream(OutputStream os, int blockSize) {
    this(os, blockSize, TarBuffer.DEFAULT_RCDSIZE);
}","public void test1818() throws Throwable {
    ByteArrayOutputStream byteArrayOutputStream0 = new ByteArrayOutputStream(2);
    BufferedOutputStream bufferedOutputStream0 = new BufferedOutputStream(byteArrayOutputStream0);
    TarArchiveOutputStream tarArchiveOutputStream0 = null;
    try {
        tarArchiveOutputStream0 = new TarArchiveOutputStream(bufferedOutputStream0, (-295));
        fail(""Expecting exception: NegativeArraySizeException"");
    } catch (NegativeArraySizeException e) {
        //
        // no message in exception (getMessage() returned null)
        //
        verifyException(""org.apache.commons.compress.archivers.tar.TarBuffer"", e);
    }
}","/**
 * Constructor for TarInputStream.
 * @param os the output stream to use
 * @param blockSize the block size to use
 */"
"@Override
public void write(byte[] wBuf, int wOffset, int numToWrite) throws IOException {
    if ((currBytes + numToWrite) > currSize) {
        throw new IOException(""request to write '"" + numToWrite + ""' bytes exceeds size in header of '"" + currSize + ""' bytes for entry '"" + currName + ""'"");
        //
        // We have to deal with assembly!!!
        // The programmer can be writing little 32 byte chunks for all
        // we know, and we must assemble complete records for writing.
        // REVIEW Maybe this should be in TarBuffer? Could that help to
        // eliminate some of the buffer copying.
        //
    }
    if (assemLen > 0) {
        if ((assemLen + numToWrite) >= recordBuf.length) {
            int aLen = recordBuf.length - assemLen;
            System.arraycopy(assemBuf, 0, recordBuf, 0, assemLen);
            System.arraycopy(wBuf, wOffset, recordBuf, assemLen, aLen);
            buffer.writeRecord(recordBuf);
            currBytes += recordBuf.length;
            wOffset += aLen;
            numToWrite -= aLen;
            assemLen = 0;
        } else {
            System.arraycopy(wBuf, wOffset, assemBuf, assemLen, numToWrite);
            wOffset += numToWrite;
            assemLen += numToWrite;
            numToWrite = 0;
        }
    }
    //
    // When we get here we have EITHER:
    // o An empty ""assemble"" buffer.
    // o No bytes to write (numToWrite == 0)
    //
    while (numToWrite > 0) {
        if (numToWrite < recordBuf.length) {
            System.arraycopy(wBuf, wOffset, assemBuf, assemLen, numToWrite);
            assemLen += numToWrite;
            break;
        }
        buffer.writeRecord(wBuf, wOffset);
        int num = recordBuf.length;
        currBytes += num;
        numToWrite -= num;
        wOffset += num;
    }
}","public void test1919() throws Throwable {
    ByteArrayOutputStream byteArrayOutputStream0 = new ByteArrayOutputStream();
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream(byteArrayOutputStream0, 2958, ""org.apache.commons.compress.archivers.zip.Zip64ExtendedInformationExtraField"");
    tarArchiveOutputStream0.write((byte[]) null, 0, 0);
}","/**
 * Writes bytes to the current tar archive entry. This method
 * is aware of the current entry and will throw an exception if
 * you attempt to write bytes past the length specified for the
 * current entry. The method is also (painfully) aware of the
 * record buffering required by TarBuffer, and manages buffers
 * that are not a multiple of recordsize in length, including
 * assembling records from small buffers.
 *
 * @param wBuf The buffer to write to the archive.
 * @param wOffset The offset in the buffer from which to get bytes.
 * @param numToWrite The number of bytes to write.
 * @throws IOException on error
 */"
"public TarArchiveOutputStream(OutputStream os, int blockSize, int recordSize, String encoding) {
    out = new CountingOutputStream(os);
    this.encoding = ZipEncodingHelper.getZipEncoding(encoding);
    this.buffer = new TarBuffer(out, blockSize, recordSize);
    this.assemLen = 0;
    this.assemBuf = new byte[recordSize];
    this.recordBuf = new byte[recordSize];
}","public void test2020() throws Throwable {
    PipedInputStream pipedInputStream0 = new PipedInputStream();
    PipedOutputStream pipedOutputStream0 = new PipedOutputStream(pipedInputStream0);
    MockPrintStream mockPrintStream0 = new MockPrintStream(pipedOutputStream0, false);
    CountingOutputStream countingOutputStream0 = new CountingOutputStream(mockPrintStream0);
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream(countingOutputStream0, 76, 9617, (String) null);
}","/**
 * Constructor for TarInputStream.
 * @param os the output stream to use
 * @param blockSize the block size to use
 * @param recordSize the record size to use
 * @param encoding name of the encoding to use for file names
 * @since Commons Compress 1.4
 */"
"@Override
public long getBytesWritten() {
    return ((CountingOutputStream) out).getBytesWritten();
}","public void test2121() throws Throwable {
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream((OutputStream) null, 3825, 3825);
    tarArchiveOutputStream0.getBytesWritten();
}",""
"@Override
public ArchiveEntry createArchiveEntry(File inputFile, String entryName) throws IOException {
    if (finished) {
        throw new IOException(""Stream has already been finished"");
    }
    return new TarArchiveEntry(inputFile, entryName);
}","public void test2222() throws Throwable {
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream((OutputStream) null, 3825, 3825);
    MockFile mockFile0 = new MockFile((File) null, """");
    tarArchiveOutputStream0.createArchiveEntry(mockFile0, ""uid"");
}","/**
 * {@inheritDoc}
 */"
"void writePaxHeaders(String entryName, Map<String, String> headers) throws IOException {
    String name = ""./PaxHeaders.X/"" + stripTo7Bits(entryName);
    // TarEntry's constructor would think this is a directory
    // and not allow any data to be written
    if (name.length() >= TarConstants.NAMELEN) {
        name = name.substring(0, TarConstants.NAMELEN - 1);
    }
    TarArchiveEntry pex = new TarArchiveEntry(name, TarConstants.LF_PAX_EXTENDED_HEADER_LC);
    StringWriter w = new StringWriter();
    for (Map.Entry<String, String> h : headers.entrySet()) {
        String key = h.getKey();
        String value = h.getValue();
        int len = key.length() + value.length() + 3 + /* blank, equals and newline */
        2;
        String line = len + "" "" + key + ""="" + value + ""\n"";
        int actualLength = line.getBytes(CharsetNames.UTF_8).length;
        while (len != actualLength) {
            // Adjust for cases where length < 10 or > 100
            // or where UTF-8 encoding isn't a single octet
            // per character.
            // Must be in loop as size may go from 99 to 100 in
            // first pass so we'd need a second.
            len = actualLength;
            line = len + "" "" + key + ""="" + value + ""\n"";
            actualLength = line.getBytes(CharsetNames.UTF_8).length;
        }
        w.write(line);
    }
    byte[] data = w.toString().getBytes(CharsetNames.UTF_8);
    pex.setSize(data.length);
    putArchiveEntry(pex);
    write(data);
    closeArchiveEntry();
}","public void test2323() throws Throwable {
    PipedOutputStream pipedOutputStream0 = new PipedOutputStream();
    FilterOutputStream filterOutputStream0 = new FilterOutputStream(pipedOutputStream0);
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream(filterOutputStream0);
    Map<String, String> map0 = ZoneId.SHORT_IDS;
    tarArchiveOutputStream0.writePaxHeaders("">mytEE(@T>JeW"", map0);
}","/**
 * Writes a PAX extended header with the given map as contents.
 * @since 1.4
 */"
"@Override
public void write(byte[] wBuf, int wOffset, int numToWrite) throws IOException {
    if ((currBytes + numToWrite) > currSize) {
        throw new IOException(""request to write '"" + numToWrite + ""' bytes exceeds size in header of '"" + currSize + ""' bytes for entry '"" + currName + ""'"");
        //
        // We have to deal with assembly!!!
        // The programmer can be writing little 32 byte chunks for all
        // we know, and we must assemble complete records for writing.
        // REVIEW Maybe this should be in TarBuffer? Could that help to
        // eliminate some of the buffer copying.
        //
    }
    if (assemLen > 0) {
        if ((assemLen + numToWrite) >= recordBuf.length) {
            int aLen = recordBuf.length - assemLen;
            System.arraycopy(assemBuf, 0, recordBuf, 0, assemLen);
            System.arraycopy(wBuf, wOffset, recordBuf, assemLen, aLen);
            buffer.writeRecord(recordBuf);
            currBytes += recordBuf.length;
            wOffset += aLen;
            numToWrite -= aLen;
            assemLen = 0;
        } else {
            System.arraycopy(wBuf, wOffset, assemBuf, assemLen, numToWrite);
            wOffset += numToWrite;
            assemLen += numToWrite;
            numToWrite = 0;
        }
    }
    //
    // When we get here we have EITHER:
    // o An empty ""assemble"" buffer.
    // o No bytes to write (numToWrite == 0)
    //
    while (numToWrite > 0) {
        if (numToWrite < recordBuf.length) {
            System.arraycopy(wBuf, wOffset, assemBuf, assemLen, numToWrite);
            assemLen += numToWrite;
            break;
        }
        buffer.writeRecord(wBuf, wOffset);
        int num = recordBuf.length;
        currBytes += num;
        numToWrite -= num;
        wOffset += num;
    }
}","public void test2424() throws Throwable {
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream((OutputStream) null, 1);
    byte[] byteArray0 = new byte[9];
    try {
        tarArchiveOutputStream0.write(byteArray0, (int) (byte) 76, (int) (byte) 97);
        fail(""Expecting exception: IOException"");
    } catch (IOException e) {
        //
        // request to write '97' bytes exceeds size in header of '0' bytes for entry 'null'
        //
        verifyException(""org.apache.commons.compress.archivers.tar.TarArchiveOutputStream"", e);
    }
}","/**
 * Writes bytes to the current tar archive entry. This method
 * is aware of the current entry and will throw an exception if
 * you attempt to write bytes past the length specified for the
 * current entry. The method is also (painfully) aware of the
 * record buffering required by TarBuffer, and manages buffers
 * that are not a multiple of recordsize in length, including
 * assembling records from small buffers.
 *
 * @param wBuf The buffer to write to the archive.
 * @param wOffset The offset in the buffer from which to get bytes.
 * @param numToWrite The number of bytes to write.
 * @throws IOException on error
 */"
"void writePaxHeaders(String entryName, Map<String, String> headers) throws IOException {
    String name = ""./PaxHeaders.X/"" + stripTo7Bits(entryName);
    // TarEntry's constructor would think this is a directory
    // and not allow any data to be written
    if (name.length() >= TarConstants.NAMELEN) {
        name = name.substring(0, TarConstants.NAMELEN - 1);
    }
    TarArchiveEntry pex = new TarArchiveEntry(name, TarConstants.LF_PAX_EXTENDED_HEADER_LC);
    StringWriter w = new StringWriter();
    for (Map.Entry<String, String> h : headers.entrySet()) {
        String key = h.getKey();
        String value = h.getValue();
        int len = key.length() + value.length() + 3 + /* blank, equals and newline */
        2;
        String line = len + "" "" + key + ""="" + value + ""\n"";
        int actualLength = line.getBytes(CharsetNames.UTF_8).length;
        while (len != actualLength) {
            // Adjust for cases where length < 10 or > 100
            // or where UTF-8 encoding isn't a single octet
            // per character.
            // Must be in loop as size may go from 99 to 100 in
            // first pass so we'd need a second.
            len = actualLength;
            line = len + "" "" + key + ""="" + value + ""\n"";
            actualLength = line.getBytes(CharsetNames.UTF_8).length;
        }
        w.write(line);
    }
    byte[] data = w.toString().getBytes(CharsetNames.UTF_8);
    pex.setSize(data.length);
    putArchiveEntry(pex);
    write(data);
    closeArchiveEntry();
}","public void test2525() throws Throwable {
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream((OutputStream) null, 2241);
    HashMap<String, String> hashMap0 = new HashMap<String, String>(2, 1);
    hashMap0.put(""org.apache.commons.compress.archivers.zip.ZipShort"", ""org.apache.commons.compress.archivers.zip.ZipShort"");
    tarArchiveOutputStream0.writePaxHeaders(""org.apache.commons.compress.archivers.zip.ZipShort"", hashMap0);
}","/**
 * Writes a PAX extended header with the given map as contents.
 * @since 1.4
 */"
"@Override
public void closeArchiveEntry() throws IOException {
    if (finished) {
        throw new IOException(""Stream has already been finished"");
    }
    if (!haveUnclosedEntry) {
        throw new IOException(""No current entry to close"");
    }
    if (assemLen > 0) {
        for (int i = assemLen; i < assemBuf.length; ++i) {
            assemBuf[i] = 0;
        }
        buffer.writeRecord(assemBuf);
        currBytes += assemLen;
        assemLen = 0;
    }
    if (currBytes < currSize) {
        throw new IOException(""entry '"" + currName + ""' closed at '"" + currBytes + ""' before the '"" + currSize + ""' bytes specified in the header were written"");
    }
    haveUnclosedEntry = false;
}","public void test2626() throws Throwable {
    ByteArrayOutputStream byteArrayOutputStream0 = new ByteArrayOutputStream();
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream(byteArrayOutputStream0);
    try {
        tarArchiveOutputStream0.closeArchiveEntry();
        fail(""Expecting exception: IOException"");
    } catch (IOException e) {
        //
        // No current entry to close
        //
        verifyException(""org.apache.commons.compress.archivers.tar.TarArchiveOutputStream"", e);
    }
}","/**
 * Close an entry. This method MUST be called for all file
 * entries that contain data. The reason is that we must
 * buffer data written to the stream in order to satisfy
 * the buffer's record based writes. Thus, there may be
 * data fragments still being assembled that must be written
 * to the output stream before this entry is closed and the
 * next entry written.
 * @throws IOException on error
 */"
"@Override
public void closeArchiveEntry() throws IOException {
    if (finished) {
        throw new IOException(""Stream has already been finished"");
    }
    if (!haveUnclosedEntry) {
        throw new IOException(""No current entry to close"");
    }
    if (assemLen > 0) {
        for (int i = assemLen; i < assemBuf.length; ++i) {
            assemBuf[i] = 0;
        }
        buffer.writeRecord(assemBuf);
        currBytes += assemLen;
        assemLen = 0;
    }
    if (currBytes < currSize) {
        throw new IOException(""entry '"" + currName + ""' closed at '"" + currBytes + ""' before the '"" + currSize + ""' bytes specified in the header were written"");
    }
    haveUnclosedEntry = false;
}","public void test2727() throws Throwable {
    MockFile mockFile0 = new MockFile("""");
    MockFile mockFile1 = new MockFile(mockFile0, ""gid"");
    MockPrintStream mockPrintStream0 = new MockPrintStream(mockFile1);
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream(mockPrintStream0);
    tarArchiveOutputStream0.close();
    try {
        tarArchiveOutputStream0.closeArchiveEntry();
        fail(""Expecting exception: IOException"");
    } catch (IOException e) {
        //
        // Stream has already been finished
        //
        verifyException(""org.apache.commons.compress.archivers.tar.TarArchiveOutputStream"", e);
    }
}","/**
 * Close an entry. This method MUST be called for all file
 * entries that contain data. The reason is that we must
 * buffer data written to the stream in order to satisfy
 * the buffer's record based writes. Thus, there may be
 * data fragments still being assembled that must be written
 * to the output stream before this entry is closed and the
 * next entry written.
 * @throws IOException on error
 */"
"void writePaxHeaders(String entryName, Map<String, String> headers) throws IOException {
    String name = ""./PaxHeaders.X/"" + stripTo7Bits(entryName);
    // TarEntry's constructor would think this is a directory
    // and not allow any data to be written
    if (name.length() >= TarConstants.NAMELEN) {
        name = name.substring(0, TarConstants.NAMELEN - 1);
    }
    TarArchiveEntry pex = new TarArchiveEntry(name, TarConstants.LF_PAX_EXTENDED_HEADER_LC);
    StringWriter w = new StringWriter();
    for (Map.Entry<String, String> h : headers.entrySet()) {
        String key = h.getKey();
        String value = h.getValue();
        int len = key.length() + value.length() + 3 + /* blank, equals and newline */
        2;
        String line = len + "" "" + key + ""="" + value + ""\n"";
        int actualLength = line.getBytes(CharsetNames.UTF_8).length;
        while (len != actualLength) {
            // Adjust for cases where length < 10 or > 100
            // or where UTF-8 encoding isn't a single octet
            // per character.
            // Must be in loop as size may go from 99 to 100 in
            // first pass so we'd need a second.
            len = actualLength;
            line = len + "" "" + key + ""="" + value + ""\n"";
            actualLength = line.getBytes(CharsetNames.UTF_8).length;
        }
        w.write(line);
    }
    byte[] data = w.toString().getBytes(CharsetNames.UTF_8);
    pex.setSize(data.length);
    putArchiveEntry(pex);
    write(data);
    closeArchiveEntry();
}","public void test2828() throws Throwable {
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream((OutputStream) null, 2241);
    HashMap<String, String> hashMap0 = new HashMap<String, String>(2, 1);
    tarArchiveOutputStream0.writePaxHeaders(""org.apache.commons.compress.archivers.zip.ZipShort"", hashMap0);
}","/**
 * Writes a PAX extended header with the given map as contents.
 * @since 1.4
 */"
"@Override
public long getBytesWritten() {
    return ((CountingOutputStream) out).getBytesWritten();
}","public void test2929() throws Throwable {
    File file0 = MockFile.createTempFile(""HLg^m']W't D%} ou"", (String) null);
    MockFileOutputStream mockFileOutputStream0 = new MockFileOutputStream(file0);
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream(mockFileOutputStream0);
    tarArchiveOutputStream0.close();
    tarArchiveOutputStream0.getBytesWritten();
}",""
"@Override
public void putArchiveEntry(ArchiveEntry archiveEntry) throws IOException {
    if (finished) {
        throw new IOException(""Stream has already been finished"");
    }
    TarArchiveEntry entry = (TarArchiveEntry) archiveEntry;
    Map<String, String> paxHeaders = new HashMap<String, String>();
    final String entryName = entry.getName();
    final ByteBuffer encodedName = encoding.encode(entryName);
    final int nameLen = encodedName.limit() - encodedName.position();
    boolean paxHeaderContainsPath = false;
    if (nameLen >= TarConstants.NAMELEN) {
        if (longFileMode == LONGFILE_POSIX) {
            paxHeaders.put(""path"", entryName);
            paxHeaderContainsPath = true;
        } else if (longFileMode == LONGFILE_GNU) {
            // create a TarEntry for the LongLink, the contents
            // of which are the entry's name
            TarArchiveEntry longLinkEntry = new TarArchiveEntry(TarConstants.GNU_LONGLINK, TarConstants.LF_GNUTYPE_LONGNAME);
            // +1 for NUL
            longLinkEntry.setSize(nameLen + 1);
            putArchiveEntry(longLinkEntry);
            write(encodedName.array(), encodedName.arrayOffset(), nameLen);
            // NUL terminator
            write(0);
            closeArchiveEntry();
        } else if (longFileMode != LONGFILE_TRUNCATE) {
            throw new RuntimeException(""file name '"" + entryName + ""' is too long ( > "" + TarConstants.NAMELEN + "" bytes)"");
        }
    }
    if (bigNumberMode == BIGNUMBER_POSIX) {
        addPaxHeadersForBigNumbers(paxHeaders, entry);
    } else if (bigNumberMode != BIGNUMBER_STAR) {
        failForBigNumbers(entry);
    }
    if (addPaxHeadersForNonAsciiNames && !paxHeaderContainsPath && !ASCII.canEncode(entryName)) {
        paxHeaders.put(""path"", entryName);
    }
    if (addPaxHeadersForNonAsciiNames && (entry.isLink() || entry.isSymbolicLink()) && !ASCII.canEncode(entry.getLinkName())) {
        paxHeaders.put(""linkpath"", entry.getLinkName());
    }
    if (paxHeaders.size() > 0) {
        writePaxHeaders(entryName, paxHeaders);
    }
    entry.writeEntryHeader(recordBuf, encoding, bigNumberMode == BIGNUMBER_STAR);
    buffer.writeRecord(recordBuf);
    currBytes = 0;
    if (entry.isDirectory()) {
        currSize = 0;
    } else {
        currSize = entry.getSize();
    }
    currName = entryName;
    haveUnclosedEntry = true;
}","public void test3030() throws Throwable {
    MockPrintStream mockPrintStream0 = new MockPrintStream(""minor device number"");
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream(mockPrintStream0, 100);
    TarArchiveEntry tarArchiveEntry0 = new TarArchiveEntry(""minor device number"", (byte) 87);
    // Undeclared exception!
    try {
        tarArchiveOutputStream0.putArchiveEntry(tarArchiveEntry0);
        fail(""Expecting exception: ArrayIndexOutOfBoundsException"");
    } catch (ArrayIndexOutOfBoundsException e) {
    }
}","/**
 * Put an entry on the output stream. This writes the entry's
 * header record and positions the output stream for writing
 * the contents of the entry. Once this method is called, the
 * stream is ready for calls to write() to write the entry's
 * contents. Once the contents are written, closeArchiveEntry()
 * <B>MUST</B> be called to ensure that all buffered data
 * is completely written to the output stream.
 *
 * @param archiveEntry The TarEntry to be written to the archive.
 * @throws IOException on error
 * @throws ClassCastException if archiveEntry is not an instance of TarArchiveEntry
 */"
"public void setAddPaxHeadersForNonAsciiNames(boolean b) {
    addPaxHeadersForNonAsciiNames = b;
}","public void test3131() throws Throwable {
    File file0 = MockFile.createTempFile(""HLg^m']W't D%} ou"", (String) null);
    MockFileOutputStream mockFileOutputStream0 = new MockFileOutputStream(file0);
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream(mockFileOutputStream0);
    tarArchiveOutputStream0.setAddPaxHeadersForNonAsciiNames(true);
}","/**
 * Whether to add a PAX extension header for non-ASCII file names.
 * @since 1.4
 */"
"public void setBigNumberMode(int bigNumberMode) {
    this.bigNumberMode = bigNumberMode;
}","public void test3232() throws Throwable {
    File file0 = MockFile.createTempFile(""HLg^m']W't D%} ou"", (String) null);
    MockFileOutputStream mockFileOutputStream0 = new MockFileOutputStream(file0);
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream(mockFileOutputStream0);
    tarArchiveOutputStream0.setBigNumberMode(977);
}","/**
 * Set the big number mode.
 * This can be BIGNUMBER_ERROR(0), BIGNUMBER_POSIX(1) or BIGNUMBER_STAR(2).
 * This specifies the treatment of big files (sizes &gt; TarConstants.MAXSIZE) and other numeric values to big to fit into a traditional tar header.
 * Default is BIGNUMBER_ERROR.
 * @param bigNumberMode the mode to use
 * @since 1.4
 */"
"@Override
public void flush() throws IOException {
    out.flush();
}","public void test3333() throws Throwable {
    File file0 = MockFile.createTempFile(""XJ_"", ""XJ_"");
    MockFileOutputStream mockFileOutputStream0 = new MockFileOutputStream(file0, false);
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream(mockFileOutputStream0, ""XJ_"");
    tarArchiveOutputStream0.flush();
}",""
"@Override
public ArchiveEntry createArchiveEntry(File inputFile, String entryName) throws IOException {
    if (finished) {
        throw new IOException(""Stream has already been finished"");
    }
    return new TarArchiveEntry(inputFile, entryName);
}","public void test3434() throws Throwable {
    ByteArrayOutputStream byteArrayOutputStream0 = new ByteArrayOutputStream();
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream(byteArrayOutputStream0, 2958, ""org.apache.commons.compress.archivers.zip.Zip64ExtendedInformationExtraField"");
    tarArchiveOutputStream0.finish();
    MockFile mockFile0 = new MockFile(""org.apache.commons.compress.archivers.zip.Zip64ExtendedInformationExtraField"", ""org.apache.commons.compress.archivers.zip.Zip64ExtendedInformationExtraField"");
    try {
        tarArchiveOutputStream0.createArchiveEntry(mockFile0, ""org.apache.commons.compress.archivers.zip.Zip64ExtendedInformationExtraField"");
        fail(""Expecting exception: IOException"");
    } catch (IOException e) {
        //
        // Stream has already been finished
        //
        verifyException(""org.apache.commons.compress.archivers.tar.TarArchiveOutputStream"", e);
    }
}","/**
 * {@inheritDoc}
 */"
"public int getRecordSize() {
    return buffer.getRecordSize();
}","public void test3535() throws Throwable {
    File file0 = MockFile.createTempFile(""HLg^m']W't D%} ou"", (String) null);
    MockFileOutputStream mockFileOutputStream0 = new MockFileOutputStream(file0);
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream(mockFileOutputStream0);
    int int0 = tarArchiveOutputStream0.getRecordSize();
    assertEquals(512, int0);
}","/**
 * Get the record size being used by this stream's TarBuffer.
 *
 * @return The TarBuffer record size.
 */"
"@Override
public void close() throws IOException {
    if (!finished) {
        finish();
    }
    if (!closed) {
        buffer.close();
        out.close();
        closed = true;
    }
}","public void test3636() throws Throwable {
    File file0 = MockFile.createTempFile(""iG+${/kZ*G4fl"", ""iG+${/kZ*G4fl"");
    MockFileOutputStream mockFileOutputStream0 = new MockFileOutputStream(file0, false);
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream(mockFileOutputStream0, 479);
    // Undeclared exception!
    try {
        tarArchiveOutputStream0.close();
        fail(""Expecting exception: ArrayIndexOutOfBoundsException"");
    } catch (ArrayIndexOutOfBoundsException e) {
    }
}","/**
 * Closes the underlying OutputStream.
 * @throws IOException on error
 */"
"@Deprecated
@Override
public int getCount() {
    return (int) getBytesWritten();
}","public void test3737() throws Throwable {
    File file0 = MockFile.createTempFile(""HLg^m']W't D%} ou"", (String) null);
    MockFileOutputStream mockFileOutputStream0 = new MockFileOutputStream(file0);
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream(mockFileOutputStream0);
    int int0 = tarArchiveOutputStream0.getCount();
    assertEquals(0, int0);
}",""
"@Override
public void putArchiveEntry(ArchiveEntry archiveEntry) throws IOException {
    if (finished) {
        throw new IOException(""Stream has already been finished"");
    }
    TarArchiveEntry entry = (TarArchiveEntry) archiveEntry;
    Map<String, String> paxHeaders = new HashMap<String, String>();
    final String entryName = entry.getName();
    final ByteBuffer encodedName = encoding.encode(entryName);
    final int nameLen = encodedName.limit() - encodedName.position();
    boolean paxHeaderContainsPath = false;
    if (nameLen >= TarConstants.NAMELEN) {
        if (longFileMode == LONGFILE_POSIX) {
            paxHeaders.put(""path"", entryName);
            paxHeaderContainsPath = true;
        } else if (longFileMode == LONGFILE_GNU) {
            // create a TarEntry for the LongLink, the contents
            // of which are the entry's name
            TarArchiveEntry longLinkEntry = new TarArchiveEntry(TarConstants.GNU_LONGLINK, TarConstants.LF_GNUTYPE_LONGNAME);
            // +1 for NUL
            longLinkEntry.setSize(nameLen + 1);
            putArchiveEntry(longLinkEntry);
            write(encodedName.array(), encodedName.arrayOffset(), nameLen);
            // NUL terminator
            write(0);
            closeArchiveEntry();
        } else if (longFileMode != LONGFILE_TRUNCATE) {
            throw new RuntimeException(""file name '"" + entryName + ""' is too long ( > "" + TarConstants.NAMELEN + "" bytes)"");
        }
    }
    if (bigNumberMode == BIGNUMBER_POSIX) {
        addPaxHeadersForBigNumbers(paxHeaders, entry);
    } else if (bigNumberMode != BIGNUMBER_STAR) {
        failForBigNumbers(entry);
    }
    if (addPaxHeadersForNonAsciiNames && !paxHeaderContainsPath && !ASCII.canEncode(entryName)) {
        paxHeaders.put(""path"", entryName);
    }
    if (addPaxHeadersForNonAsciiNames && (entry.isLink() || entry.isSymbolicLink()) && !ASCII.canEncode(entry.getLinkName())) {
        paxHeaders.put(""linkpath"", entry.getLinkName());
    }
    if (paxHeaders.size() > 0) {
        writePaxHeaders(entryName, paxHeaders);
    }
    entry.writeEntryHeader(recordBuf, encoding, bigNumberMode == BIGNUMBER_STAR);
    buffer.writeRecord(recordBuf);
    currBytes = 0;
    if (entry.isDirectory()) {
        currSize = 0;
    } else {
        currSize = entry.getSize();
    }
    currName = entryName;
    haveUnclosedEntry = true;
}","public void test3838() throws Throwable {
    TarArchiveOutputStream tarArchiveOutputStream0 = new TarArchiveOutputStream((OutputStream) null, 474, 88);
    ZipArchiveEntry zipArchiveEntry0 = new ZipArchiveEntry(""gu{f4#3*aBo5{"");
    // Undeclared exception!
    try {
        tarArchiveOutputStream0.putArchiveEntry(zipArchiveEntry0);
        fail(""Expecting exception: ClassCastException"");
    } catch (ClassCastException e) {
        //
        // org.apache.commons.compress.archivers.zip.ZipArchiveEntry cannot be cast to org.apache.commons.compress.archivers.tar.TarArchiveEntry
        //
        verifyException(""org.apache.commons.compress.archivers.tar.TarArchiveOutputStream"", e);
    }
}","/**
 * Put an entry on the output stream. This writes the entry's
 * header record and positions the output stream for writing
 * the contents of the entry. Once this method is called, the
 * stream is ready for calls to write() to write the entry's
 * contents. Once the contents are written, closeArchiveEntry()
 * <B>MUST</B> be called to ensure that all buffered data
 * is completely written to the output stream.
 *
 * @param archiveEntry The TarEntry to be written to the archive.
 * @throws IOException on error
 * @throws ClassCastException if archiveEntry is not an instance of TarArchiveEntry
 */"
